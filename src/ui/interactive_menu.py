"""Interactive Menu UI for Gemini Workflow System."""

import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import NoReturn

from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TaskID, TextColumn
from rich.prompt import Confirm, Prompt
from rich.table import Table

from src.agent import GeminiAgent
from src.analysis.cross_validation import CrossValidationSystem
from src.caching.analytics import analyze_cache_stats, print_cache_report
from src.caching.redis_cache import RedisEvalCache
from src.config import AppConfig
from src.config.constants import (
    QUERY_PREVIEW_MAX_LENGTH,
    QUERY_PREVIEW_TRUNCATE_LENGTH,
)
from src.core.models import WorkflowResult
from src.features.difficulty import AdaptiveDifficultyAdjuster
from src.features.lats import LATSSearcher
from src.processing.loader import load_input_data
from src.qa.rag_system import QAKnowledgeGraph
from src.ui.panels import (
    console,
    display_queries,
    render_budget_panel,
    render_cost_panel,
)
from src.workflow.edit import edit_content
from src.workflow.executor import execute_workflow_simple
from src.workflow.inspection import inspect_answer, inspect_query

# Constants
MENU_CHOICES = ["1", "2", "3", "4", "5"]
DEFAULT_OCR_PATH = "data/inputs/input_ocr.txt"
RETURN_TO_MENU_PROMPT = "ì—”í„°ë¥¼ ëˆŒëŸ¬ ë©”ë‰´ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤"
PROGRESS_DESCRIPTION_TEMPLATE = "[progress.description]{task.description}"
STATUS_DONE = "[green]âœ“ ì™„ë£Œ[/green]"


def _load_non_empty_file(
    prompt_label: str,
    *,
    missing_message: str,
    empty_message: str,
) -> str | None:
    file_str = Prompt.ask(prompt_label)
    file_path = Path(file_str.strip())
    if not file_path.exists():
        console.print(missing_message.format(path=file_path))
        return None
    text = file_path.read_text(encoding="utf-8")
    if not text.strip():
        console.print(empty_message)
        return None
    return text


def _load_optional_ocr_text(prompt_when_missing: str) -> str:
    ocr_file = Path(DEFAULT_OCR_PATH)
    if ocr_file.exists():
        console.print(f"[dim]ğŸ“„ OCR ìë™ ë¡œë“œ: {ocr_file}[/dim]")
        try:
            return ocr_file.read_text(encoding="utf-8")
        except OSError as exc:  # noqa: PERF203
            console.print(f"[yellow]OCR ë¡œë“œ ì‹¤íŒ¨: {exc}[/yellow]")
            return ""

    ocr_path_input = Prompt.ask(prompt_when_missing, default="")
    if not ocr_path_input:
        return ""

    ocr_path = Path(ocr_path_input.strip())
    if not ocr_path.exists():
        console.print(f"[yellow]OCR íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ocr_path}[/yellow]")
        return ""

    return ocr_path.read_text(encoding="utf-8")


def _prompt_optional_query(question_label: str, query_label: str) -> str:
    if Prompt.ask(question_label, choices=["y", "n"], default="n").lower() != "y":
        return ""
    return Prompt.ask(query_label)


def _init_answer_inspection_resources(
    agent: GeminiAgent,
    config: AppConfig,
) -> tuple[
    QAKnowledgeGraph | None,
    LATSSearcher | None,
    CrossValidationSystem | None,
    RedisEvalCache | None,
]:
    kg = QAKnowledgeGraph() if config.neo4j_uri else None
    lats = LATSSearcher(agent.llm_provider) if config.enable_lats else None
    validator = CrossValidationSystem(kg) if kg else None
    cache = RedisEvalCache() if os.getenv("REDIS_URL") else None
    return kg, lats, validator, cache


def show_error_with_guide(error_type: str, message: str, solution: str) -> None:
    """ì—ëŸ¬ ë©”ì‹œì§€ + í•´ê²° ë°©ë²• í‘œì‹œ."""
    console.print(f"\n[red]âœ— {error_type}: {message}[/red]")
    console.print(f"[dim]ğŸ’¡ í•´ê²° ë°©ë²•: {solution}[/dim]\n")


def show_main_menu() -> int:
    """ë©”ì¸ ë©”ë‰´ - ê¸°ëŠ¥ í”Œë˜ê·¸ ìƒíƒœ í‘œì‹œ í¬í•¨."""
    console.clear()

    # ê¸°ëŠ¥ í”Œë˜ê·¸ ìë™ ê°ì§€
    flags = []
    if os.getenv("NEO4J_URI"):
        flags.append("[green]Neo4j âœ“[/green]")
    if os.getenv("ENABLE_LATS", "").lower() == "true":
        flags.append("[yellow]LATS âœ“[/yellow]")
    if os.getenv("ENABLE_DATA2NEO", "").lower() == "true":
        flags.append("[blue]Data2Neo âœ“[/blue]")
    if os.getenv("REDIS_URL"):
        flags.append("[cyan]Redis âœ“[/cyan]")

    status = " | ".join(flags) if flags else "[dim]ê¸°ë³¸ ëª¨ë“œ[/dim]"

    console.print("\n[bold cyan]â•â•â• Gemini Workflow System â•â•â•[/bold cyan]")
    console.print("[dim]ê·œì¹™ ì¤€ìˆ˜ ë¦¬ë¼ì´íŒ… Â· ê²€ìˆ˜ ë°˜ë ¤ ë°©ì§€[/dim]")
    console.print(f"\nìƒíƒœ: {status}\n")

    console.print("1. ğŸ”„ ì§ˆì˜ ìƒì„± ë° í‰ê°€")
    console.print("2. âœ… ê²€ìˆ˜ (ì§ˆì˜/ë‹µë³€)")
    console.print("3. âœï¸ ìˆ˜ì • (ì‚¬ìš©ì ìš”ì²­ ê¸°ë°˜ ì¬ì‘ì„±)")
    console.print("4. ğŸ“Š ìºì‹œ í†µê³„ ë¶„ì„")
    console.print("5. ğŸšª ì¢…ë£Œ\n")

    choice = Prompt.ask("ì„ íƒ", choices=MENU_CHOICES, default="1")
    return int(choice) - 1


async def run_workflow_interactive(
    agent: GeminiAgent,
    config: AppConfig,
    logger: logging.Logger,
) -> None:
    """ì§ˆì˜ ìƒì„± ë° í‰ê°€ - ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”."""
    if not _ensure_valid_api_key(config):
        return

    ocr_file, cand_file = _prompt_workflow_input_files()
    ocr_path, cand_path = _resolve_input_paths(config, ocr_file, cand_file)

    if not _ensure_ocr_file(ocr_path):
        return
    if not _ensure_candidate_file(cand_path):
        return

    loaded = await _load_workflow_inputs(config, ocr_file, cand_file)
    if loaded is None:
        return
    ocr_text, candidates = loaded

    user_intent = Prompt.ask("ì‚¬ìš©ì ì˜ë„ (ì„ íƒ)", default="")
    queries = await _generate_queries_with_progress(agent, ocr_text, user_intent)
    if not queries:
        console.print("[yellow]ìƒì„±ëœ ì§ˆì˜ê°€ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
        return

    display_queries(queries)
    if not _confirm_queries():
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results = await _execute_queries_with_progress(
        queries,
        agent,
        ocr_text,
        candidates,
        config,
        logger,
    )
    _display_workflow_summary(queries, results, agent, config, timestamp)
    Prompt.ask(f"\n{RETURN_TO_MENU_PROMPT}")


def _ensure_valid_api_key(config: AppConfig) -> bool:
    if config.api_key and config.api_key.startswith("AIza"):
        return True
    show_error_with_guide(
        "API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
        "GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤",
        ".env íŒŒì¼ì—ì„œ GEMINI_API_KEY='AIza...'ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”",
    )
    Prompt.ask(RETURN_TO_MENU_PROMPT)
    return False


def _prompt_workflow_input_files() -> tuple[str, str]:
    ocr_file = Prompt.ask("OCR íŒŒì¼ëª…", default="input_ocr.txt")
    cand_file = Prompt.ask("í›„ë³´ ë‹µë³€ íŒŒì¼ëª…", default="input_candidates.json")
    return ocr_file, cand_file


def _resolve_input_paths(
    config: AppConfig,
    ocr_file: str,
    cand_file: str,
) -> tuple[Path, Path]:
    return config.input_dir / ocr_file, config.input_dir / cand_file


def _ensure_ocr_file(ocr_path: Path) -> bool:
    if ocr_path.exists():
        return True
    console.print(f"[red]âœ— OCR íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ocr_path}[/red]")
    if not Confirm.ask("ë¹ˆ íŒŒì¼ì„ ìƒì„±í• ê¹Œìš”?", default=True):
        return False
    ocr_path.parent.mkdir(parents=True, exist_ok=True)
    ocr_path.write_text("", encoding="utf-8")
    console.print("[green]âœ“ íŒŒì¼ ìƒì„±ë¨ - IDEì—ì„œ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”[/green]")
    return True


def _ensure_candidate_file(cand_path: Path) -> bool:
    if cand_path.exists():
        return True
    console.print(f"[red]âœ— í›„ë³´ ë‹µë³€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {cand_path}[/red]")
    if not Confirm.ask("í…œí”Œë¦¿ì„ ìƒì„±í• ê¹Œìš”?", default=True):
        return False
    import json

    template = {"a": "ì²« ë²ˆì§¸ ë‹µë³€", "b": "ë‘ ë²ˆì§¸ ë‹µë³€", "c": "ì„¸ ë²ˆì§¸ ë‹µë³€"}
    cand_path.parent.mkdir(parents=True, exist_ok=True)
    cand_path.write_text(
        json.dumps(template, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    console.print("[green]âœ“ í…œí”Œë¦¿ ìƒì„±ë¨ - IDEì—ì„œ ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”[/green]")
    return True


async def _load_workflow_inputs(
    config: AppConfig,
    ocr_file: str,
    cand_file: str,
) -> tuple[str, dict[str, str]] | None:
    try:
        return await load_input_data(config.input_dir, ocr_file, cand_file)
    except FileNotFoundError as exc:
        show_error_with_guide(
            "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
            str(exc),
            "IDEì—ì„œ data/inputs/ í´ë”ì— íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”",
        )
        Prompt.ask(RETURN_TO_MENU_PROMPT)
        return None
    except Exception as exc:  # noqa: BLE001
        import json

        if isinstance(getattr(exc, "__cause__", None), json.JSONDecodeError):
            show_error_with_guide(
                "JSON íŒŒì‹± ì˜¤ë¥˜",
                "í›„ë³´ ë‹µë³€ íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤",
                'ì˜¬ë°”ë¥¸ í˜•ì‹: {"a": "ë‹µë³€1", "b": "ë‹µë³€2", "c": "ë‹µë³€3"}',
            )
        else:
            show_error_with_guide(
                "ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨",
                str(exc),
                "íŒŒì¼ ê²½ë¡œì™€ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”",
            )
        Prompt.ask(RETURN_TO_MENU_PROMPT)
        return None


async def _generate_queries_with_progress(
    agent: GeminiAgent,
    ocr_text: str,
    user_intent: str,
) -> list[str]:
    with Progress(
        SpinnerColumn(),
        TextColumn(PROGRESS_DESCRIPTION_TEMPLATE),
        console=console,
    ) as progress:
        task = progress.add_task("ì „ëµì  ì§ˆì˜ ìƒì„± ì¤‘...", total=None)
        try:
            queries = await agent.generate_query(ocr_text, user_intent or None)
            progress.update(task, description="[green]âœ“ ì§ˆì˜ ìƒì„± ì™„ë£Œ[/green]")
            return queries
        except Exception as exc:  # noqa: BLE001
            progress.update(task, description="[red]âœ— ì§ˆì˜ ìƒì„± ì‹¤íŒ¨[/red]")
            show_error_with_guide(
                "ì§ˆì˜ ìƒì„± ì‹¤íŒ¨",
                str(exc),
                "API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”",
            )
            Prompt.ask(RETURN_TO_MENU_PROMPT)
            return []


def _confirm_queries() -> bool:
    if Confirm.ask("ìœ„ ì§ˆì˜ë“¤ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", default=True):
        return True
    console.print("[yellow]ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.[/yellow]")
    return False


async def _execute_queries_with_progress(
    queries: list[str],
    agent: GeminiAgent,
    ocr_text: str,
    candidates: dict[str, str],
    config: AppConfig,
    logger: logging.Logger,
) -> list[WorkflowResult | None]:
    console.print(f"\n[bold]âš™ï¸  {len(queries)}ê°œ ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘[/bold]\n")
    results: list[WorkflowResult | None] = []
    with Progress(
        SpinnerColumn(),
        TextColumn(PROGRESS_DESCRIPTION_TEMPLATE),
        console=console,
    ) as progress:
        for idx, query in enumerate(queries):
            turn_id = idx + 1
            task = progress.add_task(
                f"[cyan]ì§ˆì˜ {turn_id}/{len(queries)}: {query[:QUERY_PREVIEW_MAX_LENGTH]}...[/cyan]",
                total=None,
            )
            try:
                result = await execute_workflow_simple(
                    agent=agent,
                    ocr_text=ocr_text,
                    candidates=candidates,
                    config=config,
                    logger=logger,
                    query=query,
                    turn_id=turn_id,
                )
                results.append(result)
                _update_workflow_progress(progress, task, turn_id, len(queries), result)
            except Exception:  # noqa: BLE001
                logger.exception("Query %d failed", turn_id)
                progress.update(
                    task,
                    description=f"[red]âœ— ì§ˆì˜ {turn_id}/{len(queries)} ì‹¤íŒ¨[/red]",
                )
                results.append(None)
    return results


def _update_workflow_progress(
    progress: Progress,
    task_id: TaskID,
    turn_id: int,
    total_turns: int,
    result: WorkflowResult | None,
) -> None:
    if result and result.success:
        progress.update(
            task_id,
            description=f"[green]âœ“ ì§ˆì˜ {turn_id}/{total_turns} ì™„ë£Œ[/green]",
        )
        return
    progress.update(
        task_id,
        description=f"[yellow]âš  ì§ˆì˜ {turn_id}/{total_turns} ê±´ë„ˆëœ€[/yellow]",
    )


async def _handle_query_inspection(agent: GeminiAgent, config: AppConfig) -> None:
    """ì§ˆì˜ ê²€ìˆ˜ í•¸ë“¤ëŸ¬ (Direct Input -> CLI Output).

    UX ì›ì¹™:
    - ì§ˆì˜ ì§ì ‘ ì…ë ¥ (ë³µë¶™)
    - OCR ìë™ ë¡œë“œ (ë‚œì´ë„ ë¶„ì„ìš©)
    - ê²°ê³¼ ì¦‰ì‹œ CLI ì¶œë ¥ (íŒ¨ë„)
    """
    console.print(Panel("âœ… ì§ˆì˜ ê²€ìˆ˜ ëª¨ë“œ", style="cyan"))

    # [1] ì§ˆì˜ ì§ì ‘ ì…ë ¥
    query_input = Prompt.ask("\nâ“ ì§ˆì˜ ì…ë ¥ (ë³µë¶™)")
    if not query_input.strip():
        console.print("[yellow]ì§ˆì˜ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/yellow]")
        return

    # [2] OCR ìë™ ë¡œë“œ (ë‚œì´ë„ ë¶„ì„ìš©)
    ocr_text = ""
    ocr_file = Path(DEFAULT_OCR_PATH)
    if ocr_file.exists():
        console.print(f"[dim]ğŸ“„ OCR ìë™ ë¡œë“œ: {ocr_file}[/dim]")
        ocr_text = ocr_file.read_text(encoding="utf-8")
    else:
        console.print(f"[dim]OCR íŒŒì¼ ì—†ìŒ: {ocr_file} (ë‚œì´ë„ ë¶„ì„ ìƒëµ)[/dim]")

    # ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
    kg = QAKnowledgeGraph() if config.neo4j_uri else None
    lats = LATSSearcher(agent.llm_provider) if config.enable_lats else None
    difficulty = AdaptiveDifficultyAdjuster(kg) if kg else None
    cache: RedisEvalCache | None = None
    if os.getenv("REDIS_URL"):
        cache = RedisEvalCache()

    try:
        # [3] ì‹¤í–‰ & ì¶œë ¥
        with Progress(
            SpinnerColumn(),
            TextColumn(PROGRESS_DESCRIPTION_TEMPLATE),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ìµœì í™” ì¤‘...", total=None)

            # Context êµ¬ì„±
            context = {"type": "general"}

            fixed_query = await inspect_query(
                agent,
                query_input,
                ocr_text,
                context,
                kg,
                lats,
                difficulty,
                cache,
            )

            progress.update(task, completed=100, description=STATUS_DONE)

        # ê²°ê³¼ ì¦‰ì‹œ ì¶œë ¥ (íŒ¨ë„)
        result_content = (
            f"[dim]ì›ë³¸: {query_input}[/dim]\n\n"
            f"[bold green]ìˆ˜ì •: {fixed_query}[/bold green]"
        )
        console.print(Panel(result_content, title="âœ… ê²€ìˆ˜ ê²°ê³¼", border_style="green"))

    except Exception as e:
        console.print(f"[red]ê²€ìˆ˜ ì‹¤íŒ¨: {e}[/red]")
    finally:
        if kg:
            kg.close()


async def _handle_answer_inspection(agent: GeminiAgent, config: AppConfig) -> None:
    """ë‹µë³€ ê²€ìˆ˜ í•¸ë“¤ëŸ¬ (File Input -> File Output).

    UX ì›ì¹™:
    - íŒŒì¼ ê²½ë¡œ ì…ë ¥ (ê¸´ í…ìŠ¤íŠ¸)
    - OCR ìë™ ë¡œë“œ (ì‚¬ì‹¤ ê²€ì¦ìš©)
    - ê²°ê³¼ íŒŒì¼ ì €ì¥ (CLI ì¶œë ¥ ì—†ìŒ)
    """
    console.print(Panel("âœ… ë‹µë³€ ê²€ìˆ˜ ëª¨ë“œ", style="cyan"))

    # [1] íŒŒì¼ ì…ë ¥
    answer = _load_non_empty_file(
        "\nğŸ“‚ ë‹µë³€ íŒŒì¼ ê²½ë¡œ",
        missing_message="[red]íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}[/red]",
        empty_message="[yellow]ë‹µë³€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.[/yellow]",
    )
    if answer is None:
        return

    # [2] OCR ìë™ ë¡œë“œ (ì‚¬ì‹¤ ê²€ì¦ìš©)
    ocr_text = _load_optional_ocr_text("OCR íŒŒì¼ ê²½ë¡œ")

    # [3] ì§ˆì˜ ì—¬ë¶€ (ì„ íƒ)
    query = _prompt_optional_query("â“ ì§ˆì˜ ì…ë ¥?", "   ì§ˆì˜")

    kg, lats, validator, cache = _init_answer_inspection_resources(agent, config)

    try:
        # [4] ì‹¤í–‰ & ì €ì¥ (CLI ì¶œë ¥ X)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("data/outputs")
        output_path = output_dir / f"inspected_{timestamp}.md"

        with Progress(
            SpinnerColumn(),
            TextColumn(PROGRESS_DESCRIPTION_TEMPLATE),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ê²€ìˆ˜ ë° ìˆ˜ì • ì¤‘...", total=None)

            context = {"type": "general", "image_meta": {}}

            fixed_answer = await inspect_answer(
                agent,
                answer,
                query,
                ocr_text,
                context,
                kg,
                lats,
                validator,
                cache,
            )

            # ê²°ê³¼ ì €ì¥
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path.write_text(fixed_answer, encoding="utf-8")

            progress.update(task, completed=100, description=STATUS_DONE)

        console.print("\nâœ… [bold green]ì™„ë£Œ[/bold green]")
        console.print(f"ğŸ’¾ ì €ì¥ë¨: {output_path}")

    except Exception as e:
        console.print(f"[red]ê²€ìˆ˜ ì‹¤íŒ¨: {e}[/red]")
    finally:
        if kg:
            kg.close()


async def _handle_edit_menu(agent: GeminiAgent, config: AppConfig) -> None:
    """ìˆ˜ì • ë©”ë‰´ í•¸ë“¤ëŸ¬ (ì‚¬ìš©ì ìš”ì²­ ê¸°ë°˜ ì¬ì‘ì„±).

    UX ì›ì¹™:
    - ë‹µë³€ íŒŒì¼ ì…ë ¥
    - OCR ìë™ ë¡œë“œ
    - ì§ˆì˜ ì„ íƒ ì…ë ¥
    - ê°„ê²°í•œ ìˆ˜ì • ìš”ì²­ í•œ ì¤„ ì…ë ¥
    - ê²°ê³¼ íŒŒì¼ ì €ì¥ (CLI ì¶œë ¥ ì—†ìŒ)
    """
    console.print(Panel("âœï¸ ìˆ˜ì • ëª¨ë“œ: ê°„ê²°í•œ ìš”ì²­ìœ¼ë¡œ ë‚´ìš© ì¬ì‘ì„±", style="cyan"))

    # [1] ë‹µë³€ íŒŒì¼ ì…ë ¥
    answer_text = _load_non_empty_file(
        "\nğŸ“‚ ìˆ˜ì •í•  ë‹µë³€ íŒŒì¼ ê²½ë¡œ",
        missing_message="[red]âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}[/red]",
        empty_message="[yellow]ë‹µë³€ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.[/yellow]",
    )
    if answer_text is None:
        return

    # [2] OCR ìë™ ë¡œë“œ
    ocr_text = _load_optional_ocr_text("ğŸ“„ OCR íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ Enter)")
    if not ocr_text:
        console.print("[dim]âš  OCR í…ìŠ¤íŠ¸ ì—†ìŒ (ì»¨í…ìŠ¤íŠ¸ ì—†ì´ ìˆ˜ì •í•©ë‹ˆë‹¤)[/dim]")

    # [3] ì§ˆì˜ ì…ë ¥ (ì„ íƒ)
    query = _prompt_optional_query("â“ ì§ˆì˜ë¥¼ ë¬¸ë§¥ì— í¬í•¨í• ê¹Œìš”?", "   â“ ì§ˆì˜ ë‚´ìš©")

    # [4] ìˆ˜ì • ìš”ì²­ ì…ë ¥ (í•µì‹¬)
    edit_request = Prompt.ask("\nâœï¸ ì–´ë–»ê²Œ ìˆ˜ì •í• ê¹Œìš”? (í•œ ì¤„)")
    if not edit_request.strip():
        console.print("[red]âŒ ìˆ˜ì • ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤.[/red]")
        return

    # ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
    kg = QAKnowledgeGraph() if config.neo4j_uri else None

    try:
        # [5] ìˆ˜ì • ì‹¤í–‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("data/outputs")
        output_path = output_dir / f"edited_{timestamp}.md"

        with Progress(
            SpinnerColumn(),
            TextColumn(PROGRESS_DESCRIPTION_TEMPLATE),
            console=console,
        ) as progress:
            task = progress.add_task("[cyan]ìš”ì²­ì— ë”°ë¼ ë‚´ìš© ìˆ˜ì • ì¤‘...", total=None)

            edited_text = await edit_content(
                agent=agent,
                answer=answer_text,
                ocr_text=ocr_text,
                query=query,
                edit_request=edit_request.strip(),
                kg=kg,
            )

            # ê²°ê³¼ ì €ì¥
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path.write_text(edited_text, encoding="utf-8")

            progress.update(task, completed=100, description=STATUS_DONE)

        console.print("\nâœ… [bold green]ìˆ˜ì • ì™„ë£Œ[/bold green]")
        console.print(f"ğŸ’¾ ì €ì¥ë¨: {output_path}")

    except Exception as e:
        console.print(f"[red]âŒ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}[/red]")
    finally:
        if kg:
            kg.close()


def show_cache_statistics(config: AppConfig) -> None:
    """ìºì‹œ í†µê³„ ë¶„ì„."""
    console.print("\n[bold]ìºì‹œ í†µê³„ ë¶„ì„[/bold]")
    try:
        summary = analyze_cache_stats(config.cache_stats_path)
        print_cache_report(summary)
    except Exception as e:
        console.print(f"[red]í†µê³„ ë¶„ì„ ì‹¤íŒ¨: {e}[/red]")
    Prompt.ask(RETURN_TO_MENU_PROMPT)


def _display_workflow_summary(
    queries: list[str],
    results: list[WorkflowResult | None],
    agent: GeminiAgent,
    config: AppConfig,
    timestamp: str,
) -> None:
    """ì›Œí¬í”Œë¡œìš° ì™„ë£Œ í›„ ê²°ê³¼ ìš”ì•½ í‘œì‹œ."""
    console.print("\n[bold green]â•â•â• ì›Œí¬í”Œë¡œìš° ì™„ë£Œ â•â•â•[/bold green]\n")

    # ì²˜ë¦¬ ê²°ê³¼ í…Œì´ë¸”
    table = Table(title="ì²˜ë¦¬ ê²°ê³¼")
    table.add_column("#", style="cyan", width=3)
    table.add_column("ì§ˆì˜", style="white", max_width=50)
    table.add_column("ìƒíƒœ", style="green", width=8)
    table.add_column("ê²°ê³¼ íŒŒì¼", style="blue", max_width=30)

    success_count = 0
    for i, (query, result) in enumerate(zip(queries, results), 1):
        if result and result.success:
            output_file = f"result_turn_{i}_{timestamp}.md"
            status = STATUS_DONE
            success_count += 1
        else:
            output_file = "-"
            status = "[red]âœ— ì‹¤íŒ¨[/red]"

        # ì§ˆì˜ í…ìŠ¤íŠ¸ ì˜ë¼ë‚´ê¸°
        query_display = (
            query[:QUERY_PREVIEW_TRUNCATE_LENGTH] + "..."
            if len(query) > QUERY_PREVIEW_MAX_LENGTH
            else query
        )
        table.add_row(str(i), query_display, status, output_file)

    console.print(table)

    # í†µê³„ ì •ë³´
    console.print(f"\n[bold]ì„±ê³µ: {success_count}/{len(queries)}[/bold]")
    logging.getLogger(__name__).debug(
        "Workflow summary generated: %d/%d success (cache_dir=%s)",
        success_count,
        len(queries),
        config.local_cache_dir,
    )

    # ë¹„ìš©/í† í° ì •ë³´ (Budget Panel í†µí•©)
    console.print()
    console.print(render_budget_panel(agent))
    console.print(render_cost_panel(agent))


async def interactive_main(
    agent: GeminiAgent,
    config: AppConfig,
    logger: logging.Logger,
) -> None:
    """ëŒ€í™”í˜• ë©”ì¸ ë£¨í”„."""
    while True:
        try:
            choice = show_main_menu()
            await _handle_main_menu_choice(choice, agent, config, logger)
        except KeyboardInterrupt:  # noqa: PERF203
            if _confirm_return_to_menu():
                continue
        except Exception as exc:  # noqa: BLE001
            _handle_interactive_exception(exc, logger)


def _exit_interactive() -> NoReturn:
    console.print("[bold]ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”! ğŸ‘‹[/bold]")
    sys.exit(0)


async def _handle_inspection_menu(agent: GeminiAgent, config: AppConfig) -> None:
    sub_choice = Prompt.ask(
        "ê²€ìˆ˜ ìœ í˜• ì„ íƒ (1: ì§ˆì˜, 2: ë‹µë³€)",
        choices=["1", "2"],
        default="1",
    )
    handler = (
        _handle_query_inspection if sub_choice == "1" else _handle_answer_inspection
    )
    await handler(agent, config)


async def _handle_main_menu_choice(
    choice: int,
    agent: GeminiAgent,
    config: AppConfig,
    logger: logging.Logger,
) -> None:
    if choice == 0:
        await run_workflow_interactive(agent, config, logger)
        return
    if choice == 1:
        await _handle_inspection_menu(agent, config)
        return
    if choice == 2:
        await _handle_edit_menu(agent, config)
        return
    if choice == 3:
        show_cache_statistics(config)
        return
    if choice == 4:
        _exit_interactive()
    console.print(f"[red]ì•Œ ìˆ˜ ì—†ëŠ” ì„ íƒ: {choice}[/red]")


def _confirm_return_to_menu() -> bool:
    console.print("\n[yellow]âš  ì‘ì—…ì„ ì¤‘ë‹¨í•˜ì‹œê² ìŠµë‹ˆê¹Œ?[/yellow]")
    if Confirm.ask("ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°€ê¸°", default=True):
        console.print("[dim]â†’ ë©”ì¸ ë©”ë‰´ë¡œ ì´ë™í•©ë‹ˆë‹¤[/dim]\n")
        return True
    _exit_interactive()


def _handle_interactive_exception(exc: Exception, logger: logging.Logger) -> None:
    console.print(f"[red]ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {exc}[/red]")
    logger.exception("Interactive menu error")
    Prompt.ask(RETURN_TO_MENU_PROMPT)
