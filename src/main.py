# -*- coding: utf-8 -*-
import os
import sys
import logging
import asyncio
import argparse
import json
from pathlib import Path
from typing import Dict, Optional, Any, List
from datetime import datetime

# pip install python-dotenv google-generativeai aiofiles pydantic tenacity pydantic-settings jinja2 rich
from dotenv import load_dotenv
from pydantic import ValidationError
import google.generativeai as genai
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn

from rich.prompt import Confirm

from src.config import AppConfig
from src.agent import GeminiAgent
from src.models import WorkflowResult
from src.data_loader import load_input_data
from src.logging_setup import setup_logging
from src.utils import safe_json_parse
from src.exceptions import ValidationFailedError, CacheCreationError

# [Global Console] Rich Consoleì€ ì „ì—­ì—ì„œ ì¬ì‚¬ìš©
# [Global Console] Rich Consoleì€ ì „ì—­ì—ì„œ ì¬ì‚¬ìš©
console = Console()

async def reload_data_if_needed(config: AppConfig, ocr_filename: str, cand_filename: str, interactive: bool = False) -> tuple[str, Dict[str, str]]:
    """
    [Refactoring] ë°ì´í„° ë¡œë”© ë¡œì§ í†µí•©
    interactive ëª¨ë“œì¼ ê²½ìš° ì‚¬ìš©ìì—ê²Œ ì¬ë¡œë”© ì—¬ë¶€ë¥¼ ë¬¼ì–´ë³¼ ìˆ˜ ìˆê²Œ í•¨ (í˜„ì¬ëŠ” ë¡œì§ ë‹¨ìˆœí™”ë¡œ ì§ì ‘ í˜¸ì¶œ)
    """
    return await load_input_data(config.input_dir, ocr_filename, cand_filename)

def save_result_to_file(result: WorkflowResult, config: AppConfig):
    """[Config Injection] ê²°ê³¼ë¥¼ Markdown íŒŒì¼ë¡œ ì €ì¥ (í•˜ë“œì½”ë”© ì œê±°)"""
    output_dir = config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = output_dir / f"result_turn_{result.turn_id}_{timestamp}.md"
    
    content = f"""# Turn {result.turn_id} Result

## Query
{result.query}

## Evaluation
- **Best Candidate**: {result.evaluation.best_candidate}
- **Scores**:
{chr(10).join([f"  - {e.candidate_id}: {e.score} ({e.reason})" for e in result.evaluation.evaluations])}

## Best Answer ({result.evaluation.best_candidate})
{result.best_answer}

## Rewritten Answer
{result.rewritten_answer}

## Metadata
- **Cost**: ${result.cost:.4f}
- **Timestamp**: {timestamp}
"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    
    logging.getLogger("GeminiWorkflow").info(f"ê²°ê³¼ íŒŒì¼ ì €ì¥ë¨: {filename}")


async def _evaluate_and_rewrite_turn(
    agent: GeminiAgent,
    ocr_text: str,
    query: str,
    candidates: Dict[str, str],
    cache,
    turn_id: int,
    total_turns: int,
    logger: logging.Logger,
) -> Optional[WorkflowResult]:
    logger.info(f"Turn {turn_id}/{total_turns}: '{query}' ì‹¤í–‰ ì¤‘...")

    logger.info("í›„ë³´ í‰ê°€ ì¤‘...")
    evaluation = await agent.evaluate_responses(ocr_text, query, candidates, cached_content=cache)
    if not evaluation:
        logger.warning(f"Turn {turn_id}: í‰ê°€ ì‹¤íŒ¨")
        return None

    best_candidate_id = evaluation.get_best_candidate_id()
    logger.info(f"í›„ë³´ ì„ ì • ì™„ë£Œ: {best_candidate_id}")

    raw_answer = candidates.get(best_candidate_id, "")
    parsed = safe_json_parse(raw_answer, best_candidate_id)
    best_answer = parsed if parsed else raw_answer

    logger.info("ë‹µë³€ ì¬ì‘ì„± ì¤‘...")
    rewritten_answer = await agent.rewrite_best_answer(ocr_text, best_answer, cached_content=None)
    logger.info("ë‹µë³€ ì¬ì‘ì„± ì™„ë£Œ")

    return WorkflowResult(
        turn_id=turn_id,
        query=query,
        evaluation=evaluation,
        best_answer=best_answer,
        rewritten_answer=rewritten_answer,
        cost=agent.get_total_cost(),
        success=True,
    )

async def process_single_query(
    agent: GeminiAgent,
    ocr_text: str,
    query: str,
    candidates: Dict[str, str],
    cache,
    turn_id: int,
    total_turns: int,
    logger: logging.Logger,
    config: AppConfig,
    progress: Optional[Progress] = None,  # Add progress argument
    task_id: Optional[Any] = None,        # Add task_id argument
) -> Optional[WorkflowResult]:
    """
    [Parallel Processing] ë‹¨ì¼ ì§ˆì˜ ì²˜ë¦¬ (í‰ê°€ -> ì¬ì‘ì„±)
    """
    try:
        # Update progress description
        if progress and task_id:
            progress.update(task_id, description=f"[cyan]Turn {turn_id}: Processing...[/cyan]")

        result = await _evaluate_and_rewrite_turn(
            agent=agent,
            ocr_text=ocr_text,
            query=query,
            candidates=candidates,
            cache=cache,
            turn_id=turn_id,
            total_turns=total_turns,
            logger=logger,
        )
        
        if result:
            # ê²°ê³¼ ì €ì¥ (Config injection)
            save_result_to_file(result, config)
            
            # [Rich UI] í„´ ê²°ê³¼ ì¶œë ¥ (Thread-safe way needed for real app, but Rich handles it reasonably well)
            console.print(Panel(
                f"[bold]Query:[/bold] {query}\n\n"
                f"[bold]Best Candidate:[/bold] {result.evaluation.get_best_candidate_id()}\n"
                f"[bold]Rewritten:[/bold] {result.rewritten_answer[:200]}...",
                title=f"Turn {turn_id} Result",
                border_style="blue"
            ))
            
            # Mark task as completed
            if progress and task_id:
                progress.update(task_id, advance=1, description=f"[green]Turn {turn_id}: Done[/green]")
                
            return result
            
    except Exception as e:
        logger.exception(f"Turn {turn_id} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if progress and task_id:
            progress.update(task_id, description=f"[red]Turn {turn_id}: Failed[/red]")
    
    return None


async def execute_workflow(agent: GeminiAgent, ocr_text: str, user_intent: Optional[str], logger: logging.Logger, ocr_filename: str, cand_filename: str, is_interactive: bool = True) -> List[WorkflowResult]:
    """
    [Orchestration] ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Iterative & Human-in-the-Loop)
    """
    # ... (Phase 1: Planning - same as before)
    # [Phase 1: Planning] ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    logger.info("ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    queries = await agent.generate_query(ocr_text, user_intent)
    
    if not queries:
        logger.error("ì§ˆì˜ ìƒì„± ì‹¤íŒ¨")
        return []

    # [Rich UI] ìƒì„±ëœ ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    console.print(Panel(
        "\n".join([f"{i+1}. {q}" for i, q in enumerate(queries)]),
        title="[bold green]Generated Strategic Queries[/bold green]",
        border_style="green"
    ))

    # [Conditional Interactivity] AUTO ëª¨ë“œì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ ê±´ë„ˆë›°ê¸°
    config = AppConfig()
    candidates = {}  # Initialize candidates
    
    if is_interactive:
        # [Breakpoint & Hot Reload] ì‚¬ìš©ì ê°œì…
        if Confirm.ask("ìœ„ ì§ˆì˜ë¥¼ ë³´ê³  í›„ë³´ ë‹µë³€ íŒŒì¼(input_candidates.json)ì„ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ìˆ˜ì • í›„ Enter)", default=True):
            logger.info("ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ë°ì´í„° ì¬ë¡œë”© ì¤‘...")
            try:
                _, candidates = await reload_data_if_needed(config, ocr_filename, cand_filename)
                logger.info("ë°ì´í„° ì¬ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"ë°ì´í„° ì¬ë¡œë”© ì‹¤íŒ¨: {e}")
                return []
        else:
            # ì¬ë¡œë”© ì—†ì´ ì§„í–‰
            _, candidates = await reload_data_if_needed(config, ocr_filename, cand_filename)
    else:
        # [AUTO Mode] ìë™ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ (í”„ë¡¬í”„íŠ¸ ì—†ìŒ)
        logger.info("AUTO ëª¨ë“œ: ë°ì´í„° ìë™ ë¡œë”© ì¤‘...")
        _, candidates = await reload_data_if_needed(config, ocr_filename, cand_filename)

    # [Context Caching] ìºì‹œ ìƒì„± ì‹œë„
    logger.info("Context Caching ì‹œë„ ì¤‘...")
    try:
        cache = await agent.create_context_cache(ocr_text)
    except CacheCreationError as e:
        cache = None
        logger.warning(f"Context cache creation skipped: {e}")

    # [Phase 2: Execution Loop] ë³‘ë ¬ ì‹¤í–‰ (Parallel Processing) with Progress Bar
    logger.info(f"ì´ {len(queries)}ê°œì˜ ì§ˆì˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
    
    results = []
    
    # Rich Progress Bar Context
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        console=console,
        transient=True  # ì™„ë£Œ í›„ ì‚¬ë¼ì§ (ê¹”ë”í•˜ê²Œ)
    ) as progress:
        
        tasks = []
        # ì „ì²´ ì§„í–‰ë¥  íŠ¸ë˜í‚¹ìš© íƒœìŠ¤í¬ (ì„ íƒ ì‚¬í•­, ì—¬ê¸°ì„œëŠ” ê°œë³„ íƒœìŠ¤í¬ë§Œ ë³´ì—¬ì¤Œ)
        # overall_task = progress.add_task("[green]Overall Progress", total=len(queries))
        
        for i, query in enumerate(queries):
            turn_id = i + 1
            # ê° ì¿¼ë¦¬ë³„ íƒœìŠ¤í¬ ìƒì„± (ì´ˆê¸° ìƒíƒœ: Waiting)
            task_id = progress.add_task(f"[cyan]Turn {turn_id}: Waiting...", total=1)
            
            tasks.append(
                process_single_query(
                    agent=agent,
                    ocr_text=ocr_text,
                    query=query,
                    candidates=candidates,
                    cache=cache,
                    turn_id=turn_id,
                    total_turns=len(queries),
                    logger=logger,
                    config=config,
                    progress=progress,
                    task_id=task_id
                )
            )
        
        # [Concurrency] ëª¨ë“  íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰
        processed_results = await asyncio.gather(*tasks)
        
        # None ì œê±° (ì‹¤íŒ¨í•œ ê²½ìš°)
        results = [r for r in processed_results if r is not None]
        
        # ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ turn_idë¡œ ì •ë ¬ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìˆœì„œê°€ ì„ì¼ ìˆ˜ ìˆìŒ)
        results.sort(key=lambda x: x.turn_id)
    
    # [Cleanup] ìºì‹œ ì‚­ì œ
    if cache:
        try:
            cache.delete()
            logger.info(f"Cache cleaned up: {cache.name}")
        except Exception as e:
            logger.warning(f"Cache cleanup failed: {e}")

    return results

async def main():
    """Main workflow orchestrator with professional argument parsing"""
    parser = argparse.ArgumentParser(
        description="ğŸš€ Advanced Gemini Workflow: AI-powered Q&A Evaluation System",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter  # Auto-show defaults
    )

    # 1. Core Configuration
    core_group = parser.add_argument_group("Core Configuration")
    core_group.add_argument(
        "--mode",
        type=str,
        choices=["AUTO", "CHAT"],
        default="AUTO",
        help="Execution mode"
    )
    core_group.add_argument(
        "--interactive",
        action="store_true",
        help="Force interactive mode (ask for confirmation) even in AUTO mode"
    )

    # ... (rest of arguments)

    args = parser.parse_args()

    # ... (logging setup)
    logger, log_listener = setup_logging()
    
    # ... (config & resource loading)
    try:
        config = AppConfig()
        genai.configure(api_key=config.api_key)
        # ... (jinja env setup)
        from jinja2 import Environment, FileSystemLoader
        if not config.template_dir.exists():
             raise FileNotFoundError(f"Templates directory missing: {config.template_dir}")
        jinja_env = Environment(loader=FileSystemLoader(config.template_dir), autoescape=True)
        
        logger.info("ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘...")
        input_dir = config.input_dir
        ocr_text, _ = await load_input_data(input_dir, args.ocr_file, args.cand_file)

    except Exception as e:
        # ... (error handling)
        logger.critical(f"[FATAL] Initialization failed: {e}")
        log_listener.stop()
        sys.exit(1)

    # [DI] Agentì— ëª¨ë“  ì˜ì¡´ì„± ì£¼ì…
    agent = GeminiAgent(config, jinja_env=jinja_env)
    user_intent = args.intent if args.mode == "CHAT" else None
    
    logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹œì‘ (Mode: {args.mode})")

    try:
        # [Separation of Concerns] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ëª¨ë“œì— ë”°ë¼ interactive ì„¤ì •)
        # CHAT ëª¨ë“œì´ê±°ë‚˜ --interactive í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ
        is_interactive = (args.mode == "CHAT") or args.interactive
        results = await execute_workflow(agent, ocr_text, user_intent, logger, args.ocr_file, args.cand_file, is_interactive)
        
        # ... (rest of main)
        
        # [Cost Summary] ë¹„ìš© ì •ë³´ë¥¼ Panelë¡œ í‘œì‹œ
        total_cost = agent.get_total_cost()
        cost_info = f"""[bold cyan]ğŸ’° Total Session Cost:[/bold cyan] ${total_cost:.4f} USD
[bold green]ğŸ“Š Token Usage:[/bold green] {agent.total_input_tokens:,} input / {agent.total_output_tokens:,} output
[bold magenta]ğŸš€ Cache Stats:[/bold magenta] {agent.cache_hits} hits / {agent.cache_misses} misses"""
        
        console.print()
        console.print(Panel(cost_info, title="[bold blue]Cost Summary[/bold blue]", border_style="blue"))
            
    except Exception as e:
        logger.exception(f"Workflow Failed: {e}")
    finally:
        # [Cleanup] ë¡œê·¸ ë¦¬ìŠ¤ë„ˆ ì¢…ë£Œ (ë‚¨ì€ ë¡œê·¸ í”ŒëŸ¬ì‹œ)
        log_listener.stop()

if __name__ == "__main__":
    load_dotenv()
    if os.name == 'nt':
        try:
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        except AttributeError:
            pass
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        # from rich.console import Console # Already imported at the top
        console.print("\n[bold red][!] ì‚¬ìš©ì ì¤‘ë‹¨[/bold red]")
        sys.exit(130)
    except Exception as e:
        logging.critical(f"Critical error: {e}", exc_info=True)
        sys.exit(1)
