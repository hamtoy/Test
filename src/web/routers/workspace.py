"""ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸."""
# mypy: ignore-errors

from __future__ import annotations

import asyncio
import contextlib
import logging
import re
from dataclasses import dataclass
from datetime import datetime
from typing import TYPE_CHECKING, Any, Dict, Final, Optional, cast

from fastapi import APIRouter, HTTPException

if TYPE_CHECKING:
    from src.features.lats import SearchNode

from checks.detect_forbidden_patterns import find_violations
from src.agent import GeminiAgent
from src.analysis.cross_validation import CrossValidationSystem
from src.config import AppConfig
from src.config.constants import (
    DEFAULT_ANSWER_RULES,
    QA_BATCH_GENERATION_TIMEOUT,
    QA_SINGLE_GENERATION_TIMEOUT,
    WORKSPACE_GENERATION_TIMEOUT,
    WORKSPACE_UNIFIED_TIMEOUT,
)
from src.qa.pipeline import IntegratedQAPipeline
from src.qa.rag_system import QAKnowledgeGraph
from src.qa.rule_loader import RuleLoader
from src.web.models import UnifiedWorkspaceRequest, WorkspaceRequest
from src.web.response import APIMetadata, build_response
from src.web.service_registry import get_registry
from src.web.utils import (
    QTYPE_MAP,
    detect_workflow,
    load_ocr_text,
    log_review_session,
    strip_output_tags,
)
from src.workflow.edit import edit_content
from src.workflow.inspection import inspect_answer

logger = logging.getLogger(__name__)

router: APIRouter = APIRouter(prefix="/api", tags=["workspace"])

# Backward compatibility: keep global variables for modules that import them
# TODO: Remove these in future release once all routers use ServiceRegistry exclusively
_config: Optional[AppConfig] = None
agent: Optional[GeminiAgent] = None
kg: Optional[QAKnowledgeGraph] = None
pipeline: Optional[IntegratedQAPipeline] = None

# ê²€ì¦ ì¬ì‹œë„ ìµœëŒ€ íšŸìˆ˜
MAX_REWRITE_ATTEMPTS = 3


@dataclass(frozen=True)
class AnswerQualityWeights:
    """ì‹¤ì „ìš© LATS ë‹µë³€ í’ˆì§ˆ ê°€ì¤‘ì¹˜."""

    base_score: float = 0.4  # ê¸°ë³¸ 40ì 
    length_weight: float = 0.10  # ì ì ˆí•œ ê¸¸ì´ 10ì 
    number_match_weight: float = 0.25  # ìˆ«ì ì •í™•ë„ 25ì  (í•µì‹¬!)
    no_forbidden_weight: float = 0.15  # í˜•ì‹ ìœ„ë°˜ ì—†ìŒ 15ì 
    constraint_weight: float = 0.10  # Neo4j ê·œì¹™ ì¤€ìˆ˜ 10ì 

    # ê¸¸ì´ ê¸°ì¤€ (ì‹¤ì „ ìµœì í™”)
    min_length: int = 15  # ë„ˆë¬´ ì§§ì€ ë‹µë³€ ë°°ì œ
    max_length: int = 1200  # ë„ˆë¬´ ê¸´ ë‹µë³€ ë°°ì œ (ì‹¤ì œ ì‚¬ìš©ì ì„ í˜¸)

    # ìˆ«ì ì¼ì¹˜ ê¸°ì¤€ ê°•í™”
    min_number_overlap: int = 1  # ìµœì†Œ 1ê°œ ìˆ«ì ì¼ì¹˜ í•„ìˆ˜


LATS_WEIGHTS_PRESETS: Final[dict[str, AnswerQualityWeights]] = {
    # ê¸°ë³¸ ì„¤ëª…í˜• ì§ˆë¬¸
    "explanation": AnswerQualityWeights(
        number_match_weight=0.25,  # ìˆ«ì ì •í™•ë„ ì¤‘ì‹œ
        length_weight=0.15,  # ì ë‹¹í•œ ê¸¸ì´
    ),
    # í‘œ/ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ
    "table_summary": AnswerQualityWeights(
        number_match_weight=0.35,  # ìˆ«ì ì •í™•ë„ ìµœìš°ì„ 
        length_weight=0.10,
        base_score=0.35,
    ),
    # ë¹„êµ/ë¶„ì„ ì§ˆë¬¸
    "comparison": AnswerQualityWeights(
        number_match_weight=0.20,
        length_weight=0.20,  # ë¹„êµëŠ” ê¸¸ì´ê°€ ê¸¸ì–´ë„ OK
        constraint_weight=0.15,  # Neo4j ë¹„êµ ê·œì¹™ ì¤‘ì‹œ
    ),
    # íŠ¸ë Œë“œ/ì‹œê³„ì—´ ë¶„ì„
    "trend_analysis": AnswerQualityWeights(
        number_match_weight=0.30,  # ì—°ë„/ìˆ˜ì¹˜ ì •í™•ë„ í•„ìˆ˜
        constraint_weight=0.20,  # ì‹œê³„ì—´ ê·œì¹™ ì¤‘ì‹œ
    ),
    # ì—„ê²©í•œ í˜•ì‹ ìš”êµ¬ ì§ˆë¬¸
    "strict": AnswerQualityWeights(
        no_forbidden_weight=0.25,  # í˜•ì‹ ì˜¤ë¥˜ 0å®¹
        number_match_weight=0.25,
        base_score=0.30,
    ),
}

DEFAULT_LATS_WEIGHTS = LATS_WEIGHTS_PRESETS["explanation"]

_difficulty_levels = {
    "long": "ë³¸ë¬¸ì´ ê¸¸ì–´ í•µì‹¬ ìˆ«ìÂ·ê·¼ê±°ë§Œ ê°„ê²°íˆ ë‹µí•˜ì„¸ìš”.",
    "medium": "ë¶ˆí•„ìš”í•œ ì„œë¡  ì—†ì´ í•µì‹¬ì„ ì§§ê²Œ ì„œìˆ í•˜ì„¸ìš”.",
}


def set_dependencies(
    config: AppConfig,
    gemini_agent: GeminiAgent,
    kg_ref: Optional[QAKnowledgeGraph],
    qa_pipeline: Optional[IntegratedQAPipeline] = None,
) -> None:
    """ì£¼ìš” ì˜ì¡´ì„± ì£¼ì…."""
    global _config, agent, kg, pipeline
    _config = config
    agent = gemini_agent
    kg = kg_ref
    pipeline = qa_pipeline
    # Reset validator in registry
    with contextlib.suppress(RuntimeError):
        get_registry().register_validator(None)


def _get_agent() -> Optional[GeminiAgent]:
    """Registryì—ì„œ agent ê°€ì ¸ì˜¤ê¸°. ì‹¤íŒ¨ ì‹œ api ëª¨ë“ˆ fallback."""
    try:
        return get_registry().agent
    except RuntimeError:
        # api ëª¨ë“ˆ fallback (í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„±)
        try:
            from src.web import api as api_module

            if getattr(api_module, "agent", None) is not None:
                return api_module.agent
        except Exception:
            pass
        if agent is not None:
            return agent
        logger.error("Agent ì´ˆê¸°í™” ì•ˆ ë¨")
        return None


def _get_kg() -> Optional[QAKnowledgeGraph]:
    """Registryì—ì„œ KG ê°€ì ¸ì˜¤ê¸°. ì‹¤íŒ¨ ì‹œ api ëª¨ë“ˆ fallback."""
    try:
        return get_registry().kg
    except RuntimeError:
        try:
            from src.web import api as api_module

            if getattr(api_module, "kg", None) is not None:
                return api_module.kg
        except Exception:
            pass
        return kg


def _get_pipeline() -> Optional[IntegratedQAPipeline]:
    """Registryì—ì„œ pipeline ê°€ì ¸ì˜¤ê¸°. ì‹¤íŒ¨ ì‹œ api ëª¨ë“ˆ fallback."""
    try:
        return get_registry().pipeline
    except RuntimeError:
        try:
            from src.web import api as api_module

            if getattr(api_module, "pipeline", None) is not None:
                return api_module.pipeline
        except Exception:
            pass
        return pipeline


def _get_config() -> AppConfig:
    """Registryì—ì„œ config ê°€ì ¸ì˜¤ê¸°. ì‹¤íŒ¨ ì‹œ api ëª¨ë“ˆ fallback."""
    try:
        cfg = get_registry().config
    except RuntimeError:
        cfg = None
        try:
            from src.web import api as api_module

            cfg = getattr(api_module, "config", None)
        except Exception:
            pass
        if cfg is None:
            cfg = _config
        if cfg is None:
            logger.warning("Registry ì´ˆê¸°í™” ì•ˆ ë¨, ê¸°ë³¸ Config ì‚¬ìš©")
            cfg = AppConfig()

    # í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„±: timeout í•„ë“œê°€ ì •ìˆ˜ì¸ì§€ í™•ì¸ (MagicMock ë°©ì–´)
    timeout_defaults = [
        ("workspace_timeout", WORKSPACE_GENERATION_TIMEOUT),
        ("workspace_unified_timeout", WORKSPACE_UNIFIED_TIMEOUT),
        ("qa_single_timeout", QA_SINGLE_GENERATION_TIMEOUT),
        ("qa_batch_timeout", QA_BATCH_GENERATION_TIMEOUT),
    ]
    try:
        for name, default in timeout_defaults:
            val = getattr(cfg, name, None)
            if not isinstance(val, int):
                setattr(cfg, name, default)
    except Exception:
        # MagicMockì´ë‚˜ ë‹¤ë¥¸ ì˜ˆì™¸ ë°œìƒ ì‹œ ëª¨ë“  ê¸°ë³¸ê°’ ì„¤ì •
        for name, default in timeout_defaults:
            setattr(cfg, name, default)

    return cfg


def _get_validator() -> Optional[CrossValidationSystem]:
    """Registryì—ì„œ validator ê°€ì ¸ì˜¤ê¸°. ì—†ìœ¼ë©´ ìƒì„±."""
    try:
        registry = get_registry()

        # ìºì‹œëœ validator ë°˜í™˜
        if registry.validator is not None:
            return registry.validator

        # kg ì—†ìœ¼ë©´ None
        kg_instance = registry.kg
        if kg_instance is None:
            return None

        # ìƒˆë¡œ ìƒì„± ë° ë“±ë¡
        validator = CrossValidationSystem(kg_instance)
        registry.register_validator(validator)
        return validator

    except Exception as exc:
        logger.debug("Validator ì´ˆê¸°í™” ì‹¤íŒ¨: %s", exc)
        return None


def _difficulty_hint(ocr_text: str) -> str:
    length = len(ocr_text)
    if length > 4000:
        return _difficulty_levels["long"]
    if length > 2000:
        return _difficulty_levels["long"]
    return _difficulty_levels["medium"]


@router.post("/workspace")
async def api_workspace(body: WorkspaceRequest) -> Dict[str, Any]:
    """ê²€ìˆ˜ ë˜ëŠ” ììœ  ìˆ˜ì •."""
    current_agent = _get_agent()
    current_kg = _get_kg()
    if current_agent is None:
        raise HTTPException(status_code=500, detail="Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

    config = _get_config()
    ocr_text = load_ocr_text(config)
    meta_start = datetime.now()

    async def _run_workspace() -> Dict[str, Any]:
        if body.mode == "inspect":
            fixed = await inspect_answer(
                agent=current_agent,
                answer=body.answer,
                query=body.query or "",
                ocr_text=ocr_text,
                context={},
                kg=current_kg,
                validator=_get_validator(),
                cache=None,
            )

            log_review_session(
                mode="inspect",
                question=body.query or "",
                answer_before=body.answer,
                answer_after=fixed,
                edit_request_used="",
                inspector_comment=body.inspector_comment or "",
            )

            return {
                "mode": "inspect",
                "result": {
                    "original": body.answer,
                    "fixed": fixed,
                    "changes": ["ìë™ êµì • ì™„ë£Œ"],
                },
            }

        if not body.edit_request:
            raise HTTPException(status_code=400, detail="edit_requestê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        edited = await edit_content(
            agent=current_agent,
            answer=body.answer,
            ocr_text=ocr_text,
            query=body.query or "",
            edit_request=body.edit_request,
            kg=current_kg,
            cache=None,
        )

        log_review_session(
            mode="edit",
            question=body.query or "",
            answer_before=body.answer,
            answer_after=edited,
            edit_request_used=body.edit_request,
            inspector_comment=body.inspector_comment or "",
        )

        return {
            "mode": "edit",
            "result": {
                "original": body.answer,
                "edited": edited,
                "request": body.edit_request,
            },
        }

    try:
        result = await asyncio.wait_for(
            _run_workspace(), timeout=config.workspace_timeout
        )
        duration = (datetime.now() - meta_start).total_seconds()
        meta = APIMetadata(duration=duration)
        return cast(
            Dict[str, Any], build_response(result, metadata=meta, config=config)
        )
    except asyncio.TimeoutError:
        raise HTTPException(
            status_code=504,
            detail=f"ì‘ì—… ì‹œê°„ ì´ˆê³¼ ({config.workspace_timeout}ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )
    except Exception as e:
        logger.error("ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì‘ì—… ì‹¤íŒ¨: %s", e)
        raise HTTPException(status_code=500, detail=f"ì‘ì—… ì‹¤íŒ¨: {str(e)}")


@router.post("/workspace/generate-answer")
async def api_generate_answer_from_query(body: Dict[str, Any]) -> Dict[str, Any]:
    """ì§ˆë¬¸ ê¸°ë°˜ ë‹µë³€ ìƒì„± - Neo4j ê·œì¹™ ë™ì  ì£¼ì…."""
    current_agent = _get_agent()
    current_kg = _get_kg()
    if current_agent is None:
        raise HTTPException(status_code=500, detail="Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

    query = body.get("query", "")
    config = _get_config()
    ocr_text = body.get("ocr_text") or load_ocr_text(config)
    meta_start = datetime.now()
    query_type = body.get("query_type", "explanation")
    normalized_qtype = QTYPE_MAP.get(query_type, "explanation")

    rule_loader = RuleLoader(current_kg)
    rules_list = rule_loader.get_rules_for_type(normalized_qtype, DEFAULT_ANSWER_RULES)

    try:
        rules_text = "\n".join(f"- {r}" for r in rules_list)
        prompt = f"""[ì§€ì‹œì‚¬í•­]
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
OCRì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
í‘œ/ê·¸ë˜í”„/ì°¨íŠ¸ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³  í…ìŠ¤íŠ¸ ê·¼ê±°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
<output> íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

[ì¤€ìˆ˜ ê·œì¹™]
{rules_text}

[OCR í…ìŠ¤íŠ¸]
{ocr_text[:3000]}

[ì§ˆì˜]
{query}

        ìœ„ OCR í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆì˜ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”."""

        answer = await asyncio.wait_for(
            current_agent.rewrite_best_answer(
                ocr_text=ocr_text,
                best_answer=prompt,
                cached_content=None,
                query_type=normalized_qtype,
            ),
            timeout=config.workspace_timeout,
        )

        answer = strip_output_tags(answer)

        # ê²€ì¦ ë° ì¬ì‹œë„ (ìµœëŒ€ MAX_REWRITE_ATTEMPTSíšŒ)
        for attempt in range(MAX_REWRITE_ATTEMPTS):
            violations = find_violations(answer)
            if not violations:
                break

            if attempt < MAX_REWRITE_ATTEMPTS - 1:
                violation_types = ", ".join(set(v["type"] for v in violations))
                logger.warning(
                    "ë‹µë³€ì— ê¸ˆì§€ íŒ¨í„´ ë°œê²¬ (ì‹œë„ %d/%d): %s",
                    attempt + 1,
                    MAX_REWRITE_ATTEMPTS,
                    violation_types,
                )
                answer = await asyncio.wait_for(
                    current_agent.rewrite_best_answer(
                        ocr_text=ocr_text,
                        best_answer=answer,
                        edit_request=f"í•œêµ­ì–´ë¡œ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ë‹¤ìŒ íŒ¨í„´ ì œê±°: {violation_types}. <output> íƒœê·¸ ì‚¬ìš© ê¸ˆì§€.",
                        cached_content=None,
                        query_type=normalized_qtype,
                    ),
                    timeout=config.workspace_timeout,
                )
                answer = strip_output_tags(answer)
            else:
                logger.error(
                    "ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ë§ˆì§€ë§‰ ë‹µë³€ ë°˜í™˜ (violations: %d)",
                    len(violations),
                )

        duration = (datetime.now() - meta_start).total_seconds()
        meta = APIMetadata(duration=duration)
        return cast(
            Dict[str, Any],
            build_response(
                {"query": query, "answer": answer}, metadata=meta, config=config
            ),
        )
    except asyncio.TimeoutError:
        raise HTTPException(
            status_code=504,
            detail=f"ë‹µë³€ ìƒì„± ì‹œê°„ ì´ˆê³¼ ({config.workspace_timeout}ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/workspace/generate-query")
async def api_generate_query_from_answer(body: Dict[str, Any]) -> Dict[str, Any]:
    """ë‹µë³€ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±."""
    current_agent = _get_agent()
    if current_agent is None:
        raise HTTPException(status_code=500, detail="Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

    answer = body.get("answer", "")
    config = _get_config()
    ocr_text = body.get("ocr_text") or load_ocr_text(config)
    meta_start = datetime.now()

    try:
        prompt = f"""
ë‹¤ìŒ ë‹µë³€ì— ê°€ì¥ ì í•©í•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.

[OCR í…ìŠ¤íŠ¸]
{ocr_text[:1000]}

[ë‹µë³€]
{answer}

        ìœ„ ë‹µë³€ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”. ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
        queries = await asyncio.wait_for(
            current_agent.generate_query(prompt, user_intent=None),
            timeout=config.workspace_timeout,
        )
        query = queries[0] if queries else "ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨"

        duration = (datetime.now() - meta_start).total_seconds()
        meta = APIMetadata(duration=duration)
        return cast(
            Dict[str, Any],
            build_response(
                {"query": query, "answer": answer}, metadata=meta, config=config
            ),
        )
    except asyncio.TimeoutError:
        raise HTTPException(
            status_code=504,
            detail=f"ì§ˆì˜ ìƒì„± ì‹œê°„ ì´ˆê³¼ ({config.workspace_timeout}ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def _generate_lats_answer(
    query: str,
    ocr_text: str,
    query_type: str,
) -> tuple[str, dict[str, Any]]:
    """LATSë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ë‹µë³€ í›„ë³´ ìƒì„± ë° í‰ê°€ í›„ ìµœì  ì„ íƒ."""
    current_agent = _get_agent()
    if not current_agent:
        return "", {}

    # ğŸ”§ ìë™ ê°€ì¤‘ì¹˜ ì„ íƒ (ì‹¤ì „ ìµœì í™”)
    weights = LATS_WEIGHTS_PRESETS.get(query_type, DEFAULT_LATS_WEIGHTS)
    logger.info("LATS ì‹¤í–‰: %s (weights: %s)", query_type, weights.__class__.__name__)

    # ê° ì „ëµë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    strategies = [
        {
            "name": "ìˆ«ì_ì¤‘ì‹¬",
            "instruction": "OCR í…ìŠ¤íŠ¸ì— ìˆëŠ” ëª¨ë“  ì£¼ìš” ìˆ«ìì™€ ìˆ˜ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
        },
        {
            "name": "íŠ¸ë Œë“œ_ì¤‘ì‹¬",
            "instruction": "ì‹œê°„ì— ë”°ë¥¸ ë³€í™”, ì¦ê°€/ê°ì†Œ ì¶”ì„¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
        },
        {
            "name": "ë¹„êµ_ì¤‘ì‹¬",
            "instruction": "ì„œë¡œ ë‹¤ë¥¸ í•­ëª©ë“¤ì˜ ì°¨ì´ì ê³¼ ë¹„êµë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.",
        },
    ]

    # ê° ì „ëµìœ¼ë¡œ ë‹µë³€ ìƒì„± ë° í‰ê°€
    candidates: list[dict[str, Any]] = []
    for strategy in strategies:
        prompt = f"""[ì§ˆì˜]
{query}

[OCR í…ìŠ¤íŠ¸]
{ocr_text[:2000]}

[ë‹µë³€ ì „ëµ: {strategy["name"]}]
{strategy["instruction"]}

ìœ„ OCR í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ë¶ˆë¦¿ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""

        try:
            system_prompt = (
                "ë‹¹ì‹ ì€ í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ì„ ì‘ì„±í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
            )
            model = current_agent._create_generative_model(system_prompt)  # noqa: SLF001
            answer = await current_agent._call_api_with_retry(model, prompt)  # noqa: SLF001
            answer = strip_output_tags(answer.strip())

            if answer and len(answer) > weights.min_length:
                # ë‹µë³€ í‰ê°€
                score = await _evaluate_answer_quality(
                    answer, ocr_text, query_type, weights
                )

                if score >= 0.6:  # í’ˆì§ˆ ì„ê³„ê°’ (ì‹¤ì „ ê¸°ì¤€)
                    candidates.append(
                        {
                            "strategy": strategy["name"],
                            "answer": answer,
                            "score": score,
                        }
                    )
                    logger.info("âœ… LATS í›„ë³´: %s (%.2f)", strategy["name"], score)
        except Exception as e:
            logger.debug("LATS ë‹µë³€ ìƒì„± ì‹¤íŒ¨ (%s): %s", strategy["name"], e)
            continue

    if not candidates:
        logger.warning("LATS ëª¨ë“  í›„ë³´ ì €í’ˆì§ˆ, ê¸°ë³¸ ë‹µë³€ ë°˜í™˜")
        return "", {"reason": "all_low_quality"}

    # ìµœê³  ì ìˆ˜ ë‹µë³€ ì„ íƒ
    best = max(candidates, key=lambda x: float(x["score"]))
    meta = {
        "query_type": query_type,
        "weights_used": vars(weights),
        "best_strategy": best["strategy"],
        "best_score": best["score"],
        "candidates": len(candidates),
        "avg_score": sum(c["score"] for c in candidates) / len(candidates),
    }

    return str(best["answer"]), meta


async def _evaluate_answer_quality(
    answer: str,
    ocr_text: str,
    query_type: str = "explanation",
    weights: AnswerQualityWeights | None = None,
) -> float:
    """ì‹¤ì „ìš© ê³ í’ˆì§ˆ ë‹µë³€ í‰ê°€ (0.0-1.0)."""
    if not answer or len(answer) < 5:
        logger.debug("ë‹µë³€ ë„ˆë¬´ ì§§ìŒ: %dì", len(answer))
        return 0.0

    weights = weights or LATS_WEIGHTS_PRESETS.get(query_type, DEFAULT_LATS_WEIGHTS)

    score_details = {"weights": vars(weights), "failures": []}
    score = weights.base_score

    # 1ï¸âƒ£ ê¸¸ì´ ê²€ì¦ (ì‹¤ì‚¬ìš©ì ì„ í˜¸ ê¸°ì¤€)
    if weights.min_length <= len(answer) <= weights.max_length:
        score += weights.length_weight
    else:
        score_details["failures"].append(f"length({len(answer)})")

    # 2ï¸âƒ£ ìˆ«ì ì •í™•ë„ (í•µì‹¬ í’ˆì§ˆ ì§€í‘œ!)
    ocr_numbers = set(re.findall(r"\d+(?:\.\d+)?", ocr_text))
    answer_numbers = set(re.findall(r"\d+(?:\.\d+)?", answer))
    overlap = len(answer_numbers & ocr_numbers)

    if overlap >= weights.min_number_overlap and ocr_numbers:
        score += weights.number_match_weight
        score_details["numbers"] = {"overlap": overlap, "total_ocr": len(ocr_numbers)}
    elif not ocr_numbers:
        # OCRì— ìˆ«ìê°€ ì—†ìœ¼ë©´ ê°ì  ì—†ì´ ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬
        score += weights.number_match_weight * 0.5
    else:
        score_details["failures"].append(f"numbers({overlap}/{len(ocr_numbers)})")

    # 3ï¸âƒ£ ê¸ˆì§€ íŒ¨í„´ (ë§ˆí¬ë‹¤ìš´ ë¶ˆë¦¿ ë“±)
    forbidden_patterns = [r"^\s*[-*â€¢]\s", r"\*\*", r"__"]
    has_forbidden = any(re.search(p, answer, re.MULTILINE) for p in forbidden_patterns)
    if not has_forbidden:
        score += weights.no_forbidden_weight
    else:
        score_details["failures"].append("forbidden_patterns")

    # 4ï¸âƒ£ Neo4j ì œì•½ì‚¬í•­ (ì„ íƒ)
    kg = _get_kg()
    if kg and weights.constraint_weight > 0:
        try:
            # ê°„ë‹¨í•œ ê·œì¹™ ê²€ì¦ (ì‹¤ì œë¡œëŠ” KGë³„ ê·œì¹™ ì ìš©)
            score += weights.constraint_weight * 0.8  # ë³´ìˆ˜ì  ì ìš©
        except Exception:
            score_details["failures"].append("constraints")

    final_score = min(1.0, max(0.0, score))

    # ë¡œê¹… (ì‹¤ì „ ë””ë²„ê¹…ìš©)
    if final_score < 0.7:  # ì €í’ˆì§ˆ ë‹µë³€ë§Œ ë¡œê¹…
        logger.warning(
            "ì €í’ˆì§ˆ LATS ë‹µë³€ (%.2f): %s, ì‹¤íŒ¨: %s",
            final_score,
            query_type,
            ", ".join(cast(list[str], score_details["failures"])),
        )

    logger.debug("LATS ì ìˆ˜: %.2f (%s)", final_score, score_details)
    return final_score


async def _lats_evaluate_answer(node: "SearchNode") -> float:
    """LATS í‰ê°€: ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì„ 0.0-1.0ë¡œ ì ìˆ˜í™”."""
    # SearchStateì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    state = node.state
    current_answer = state.current_answer or ""
    ocr_text = state.ocr_text or ""

    # query_type ì¶”ì¶œ (metadataë‚˜ query_type í•„ë“œ í™•ì¸)
    query_type = "explanation"
    if hasattr(state, "metadata") and state.metadata:
        query_type = state.metadata.get("query_type", "explanation")
    elif hasattr(state, "query_type") and state.query_type:
        query_type = state.query_type

    if not current_answer:
        return 0.0

    # ê°€ì¤‘ì¹˜ ì ìš©
    weights = LATS_WEIGHTS_PRESETS.get(query_type, DEFAULT_LATS_WEIGHTS)

    score = weights.base_score
    score_details = {"weights": vars(weights), "failures": []}

    # 1. ê¸¸ì´ ê²€ì¦
    if weights.min_length <= len(current_answer) <= weights.max_length:
        score += weights.length_weight
    else:
        score_details["failures"].append(f"length({len(current_answer)})")

    # 2. OCR ìˆ«ì í¬í•¨ ê²€ì¦
    ocr_numbers = set(re.findall(r"\d+(?:\.\d+)?", ocr_text))
    answer_numbers = set(re.findall(r"\d+(?:\.\d+)?", current_answer))
    overlap = len(answer_numbers & ocr_numbers)

    if overlap >= weights.min_number_overlap and ocr_numbers:
        score += weights.number_match_weight
    elif not ocr_numbers:
        score += weights.number_match_weight * 0.5

    # 3. ê¸ˆì§€ íŒ¨í„´ ê²€ì¦
    forbidden_patterns = [r"^\s*[-*â€¢]\s", r"\*\*", r"__"]
    has_forbidden = any(
        re.search(p, current_answer, re.MULTILINE) for p in forbidden_patterns
    )
    if not has_forbidden:
        score += weights.no_forbidden_weight

    # 4. Neo4j ì œì•½ì‚¬í•­ ê²€ì¦
    current_kg = _get_kg()
    if current_kg and weights.constraint_weight > 0:
        with contextlib.suppress(Exception):
            score += weights.constraint_weight * 0.8

    final_score = min(1.0, max(0.0, score))

    # ë¡œê¹… (10% í™•ë¥  ë˜ëŠ” ì €í’ˆì§ˆì¼ ë•Œë§Œ)
    if final_score < 0.6:
        logger.debug("LATS Node í‰ê°€ (%.2f): %s", final_score, query_type)

    return final_score


@router.post("/workspace/unified")
async def api_unified_workspace(body: UnifiedWorkspaceRequest) -> Dict[str, Any]:
    """í†µí•© ì›Œí¬ìŠ¤í˜ì´ìŠ¤ - WorkspaceExecutor ê¸°ë°˜ êµ¬í˜„."""
    from src.workflow.workspace_executor import (
        WorkflowContext,
        WorkflowType,
        WorkspaceExecutor,
    )

    # Get services from registry
    current_agent = _get_agent()
    current_kg = _get_kg()
    current_pipeline = _get_pipeline()
    config = _get_config()
    meta_start = datetime.now()

    if current_agent is None:
        raise HTTPException(status_code=500, detail="Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

    # Load OCR text
    ocr_text = body.ocr_text or load_ocr_text(config)

    # Detect workflow
    workflow_str = detect_workflow(
        body.query or "", body.answer or "", body.edit_request or ""
    )

    try:
        workflow_type = WorkflowType(workflow_str)
    except ValueError:
        raise HTTPException(
            status_code=400, detail=f"ì•Œ ìˆ˜ ì—†ëŠ” ì›Œí¬í”Œë¡œìš°: {workflow_str}"
        )

    # Build context
    context = WorkflowContext(
        query=body.query or "",
        answer=body.answer or "",
        ocr_text=ocr_text,
        query_type=body.query_type or "global_explanation",
        edit_request=body.edit_request or "",
        global_explanation_ref=body.global_explanation_ref or "",
        use_lats=body.use_lats or False,
    )

    # Create executor and execute workflow
    executor = WorkspaceExecutor(
        agent=current_agent,
        kg=current_kg,
        pipeline=current_pipeline,
        config=config,
        edit_fn=edit_content,
    )

    try:
        result = await asyncio.wait_for(
            executor.execute(workflow_type, context),
            timeout=config.workspace_unified_timeout,
        )

        # Build response
        duration = (datetime.now() - meta_start).total_seconds()
        meta = APIMetadata(duration=duration)

        result_dict = {
            "workflow": result.workflow,
            "query": result.query,
            "answer": result.answer,
            "changes": result.changes,
            "query_type": result.query_type,
        }

        return cast(
            Dict[str, Any], build_response(result_dict, metadata=meta, config=config)
        )

    except asyncio.TimeoutError:
        raise HTTPException(
            status_code=504,
            detail=f"ì›Œí¬í”Œë¡œìš° ì‹œê°„ ì´ˆê³¼ ({config.workspace_unified_timeout}ì´ˆ). ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error("ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: %s", e, exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")


__all__ = [
    "api_generate_answer_from_query",
    "api_generate_query_from_answer",
    "api_unified_workspace",
    "api_workspace",
    "router",
    "set_dependencies",
]
