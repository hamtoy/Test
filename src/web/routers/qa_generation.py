# mypy: allow-untyped-decorators
"""QA ìƒì„± ì—”ë“œí¬ì¸íŠ¸."""

from __future__ import annotations

import asyncio
import hashlib
import logging
import re
import traceback
from datetime import datetime
from typing import Any, cast

from fastapi import APIRouter, HTTPException
from tenacity import retry, stop_after_attempt, wait_exponential

from checks.detect_forbidden_patterns import find_formatting_violations, find_violations
from src.agent import GeminiAgent
from src.config.constants import (
    DEFAULT_ANSWER_RULES,
    ESTIMATED_CACHE_HIT_TIME_SAVINGS,
    QA_BATCH_TYPES,
    QA_BATCH_TYPES_THREE,
    QA_CACHE_OCR_TRUNCATE_LENGTH,
    QA_GENERATION_OCR_TRUNCATE_LENGTH,
)
from src.config.exceptions import SafetyFilterError
from src.processing.example_selector import DynamicExampleSelector
from src.qa.rule_loader import RuleLoader
from src.qa.validator import UnifiedValidator, validate_constraints
from src.web.cache import answer_cache
from src.web.models import GenerateQARequest
from src.web.response import APIMetadata, build_response
from src.web.utils import QTYPE_MAP, load_ocr_text, postprocess_answer

from .qa_common import (
    _difficulty_hint,
    _get_agent,
    _get_config,
    _get_kg,
    _get_pipeline,
    _get_validator_class,
    get_cached_kg,
    logger,
)

router = APIRouter(prefix="/api", tags=["qa-generation"])


@router.get("/qa/cache/stats")
async def get_cache_stats() -> dict[str, Any]:
    """Get cache statistics (PHASE 2B: Performance monitoring).

    Returns:
        Cache metrics including hit rate, size, and performance impact
    """
    stats = answer_cache.get_stats()
    # Add estimated time saved (use ESTIMATED_CACHE_HIT_TIME_SAVINGS constant)
    time_saved_seconds = stats["hits"] * ESTIMATED_CACHE_HIT_TIME_SAVINGS
    stats["estimated_time_saved_seconds"] = time_saved_seconds
    stats["estimated_time_saved_minutes"] = round(time_saved_seconds / 60, 2)

    return {
        "success": True,
        "data": stats,
        "message": f"Cache hit rate: {stats['hit_rate_percent']:.1f}%",
    }


@router.post("/qa/cache/clear")
async def clear_cache() -> dict[str, Any]:
    """Clear all cached answers (PHASE 2B: Cache management).

    Returns:
        Success message with number of entries cleared
    """
    size_before = answer_cache.get_stats()["cache_size"]
    await answer_cache.clear()

    return {
        "success": True,
        "data": {"entries_cleared": size_before},
        "message": f"Cleared {size_before} cache entries",
    }


@router.post("/qa/generate")
async def api_generate_qa(body: GenerateQARequest) -> dict[str, Any]:
    """QA ìƒì„± (ë°°ì¹˜: ì „ì²´ ì„¤ëª… ì„ í–‰ í›„ ë³‘ë ¬, ë‹¨ì¼: íƒ€ìž…ë³„ ìƒì„±)."""
    current_agent = _get_agent()
    if current_agent is None:
        raise HTTPException(status_code=500, detail="Agent ì´ˆê¸°í™” ì‹¤íŒ¨")

    ocr_text = body.ocr_text or load_ocr_text(_get_config())

    try:
        start = datetime.now()
        if body.mode in {"batch", "batch_three"}:
            # Wrap entire batch processing in timeout
            async def _process_batch() -> dict[str, Any]:
                results: list[dict[str, Any]] = []

                batch_types = body.batch_types or QA_BATCH_TYPES
                if body.mode == "batch_three" and body.batch_types is None:
                    batch_types = QA_BATCH_TYPES_THREE
                if not batch_types:
                    raise HTTPException(
                        status_code=400,
                        detail="batch_typesì´ ë¹„ì–´ ìžˆìŠµë‹ˆë‹¤.",
                    )

                first_type = batch_types[0]
                first_query: str = ""

                # 1ë‹¨ê³„: global_explanation ìˆœì°¨ ìƒì„±
                try:
                    first_pair = await asyncio.wait_for(
                        generate_single_qa_with_retry(
                            current_agent, ocr_text, first_type
                        ),
                        timeout=_get_config().qa_single_timeout,
                    )
                    results.append(first_pair)
                    first_query = first_pair.get("query", "")
                except Exception as exc:  # noqa: BLE001
                    logger.error("%s ìƒì„± ì‹¤íŒ¨: %s", first_type, exc)
                    results.append(
                        {
                            "type": first_type,
                            "query": "ìƒì„± ì‹¤íŒ¨",
                            "answer": f"ì¼ì‹œì  ì˜¤ë¥˜: {str(exc)[:100]}",
                        },
                    )

                # 2ë‹¨ê³„: ë‚˜ë¨¸ì§€ íƒ€ìž… 2ê°œì”© ë³‘ë ¬ ìƒì„± (Rate Limit ë°©ì§€ìš© 1ì´ˆ ë”œë ˆì´)
                remaining_types = batch_types[1:]
                previous_queries = [first_query] if first_query else []

                # 2ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬ (ì™„ì „ ë³‘ë ¬ë³´ë‹¤ ì•ˆì „, ì™„ì „ ìˆœì°¨ë³´ë‹¤ ë¹ ë¦„)
                for i in range(0, len(remaining_types), 2):
                    batch = remaining_types[i : i + 2]

                    # ì²« ë²ˆì§¸ ë°°ì¹˜ê°€ ì•„ë‹ˆë©´ ë”œë ˆì´ ì¶”ê°€ (Rate Limit ë°©ì§€)
                    if i > 0:
                        await asyncio.sleep(0.5)  # 1.0ì´ˆ â†’ 0.5ì´ˆë¡œ ë‹¨ì¶•

                    logger.info("â³ %s íƒ€ìž… ìƒì„± ì‹œìž‘", ", ".join(batch))

                    batch_results = await asyncio.gather(
                        *[
                            generate_single_qa_with_retry(
                                current_agent,
                                ocr_text,
                                qtype,
                                previous_queries=previous_queries
                                if previous_queries
                                else None,
                            )
                            for qtype in batch
                        ],
                        return_exceptions=True,
                    )

                    for j, pair in enumerate(batch_results):
                        qtype = batch[j]
                        if isinstance(pair, Exception):
                            import sys

                            tb_str = "".join(
                                traceback.format_exception(
                                    type(pair), pair, pair.__traceback__
                                )
                            )
                            sys.stderr.write(
                                f"\n[ERROR TRACEBACK] {qtype}:\n{tb_str}\n"
                            )
                            logger.error("%s ìƒì„± ì‹¤íŒ¨:\n%s", qtype, tb_str)
                            results.append(
                                {
                                    "type": qtype,
                                    "query": "ìƒì„± ì‹¤íŒ¨",
                                    "answer": f"ì¼ì‹œì  ì˜¤ë¥˜: {str(pair)[:100]}",
                                },
                            )
                        else:
                            results.append(cast("dict[str, Any]", pair))
                            pair_dict = cast("dict[str, Any]", pair)
                            if (
                                pair_dict.get("query")
                                and pair_dict.get("query") != "ìƒì„± ì‹¤íŒ¨"
                            ):
                                previous_queries.append(pair_dict.get("query", ""))

                duration = (datetime.now() - start).total_seconds()
                meta = APIMetadata(duration=duration)
                return cast(
                    "dict[str, Any]",
                    build_response(
                        {"mode": "batch", "pairs": results},
                        metadata=meta,
                        config=_get_config(),
                    ),
                )

            return await asyncio.wait_for(
                _process_batch(),
                timeout=_get_config().qa_batch_timeout,
            )

        if not body.qtype:
            raise HTTPException(status_code=400, detail="qtypeì´ í•„ìš”í•©ë‹ˆë‹¤.")
        pair = await asyncio.wait_for(
            generate_single_qa(current_agent, ocr_text, body.qtype),
            timeout=_get_config().qa_single_timeout,
        )
        duration = (datetime.now() - start).total_seconds()
        meta = APIMetadata(duration=duration)
        return cast(
            "dict[str, Any]",
            build_response(
                {"mode": "single", "pair": pair},
                metadata=meta,
                config=_get_config(),
            ),
        )

    except asyncio.TimeoutError:
        timeout_msg = (
            f"ìƒì„± ì‹œê°„ ì´ˆê³¼ ({_get_config().qa_batch_timeout if body.mode in {'batch', 'batch_three'} else _get_config().qa_single_timeout}ì´ˆ). "
            "ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
        raise HTTPException(status_code=504, detail=timeout_msg)
    except Exception as e:
        logger.error("QA ìƒì„± ì‹¤íŒ¨: %s\n%s", e, traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"ìƒì„± ì‹¤íŒ¨: {e!s}")


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    reraise=True,
)
async def generate_single_qa_with_retry(
    agent: GeminiAgent,
    ocr_text: str,
    qtype: str,
    previous_queries: list[str] | None = None,
) -> dict[str, Any]:
    """ìž¬ì‹œë„ ë¡œì§ì´ ìžˆëŠ” QA ìƒì„± ëž˜í¼."""
    return await generate_single_qa(agent, ocr_text, qtype, previous_queries)


async def generate_single_qa(
    agent: GeminiAgent,
    ocr_text: str,
    qtype: str,
    previous_queries: list[str] | None = None,
) -> dict[str, Any]:
    """ë‹¨ì¼ QA ìƒì„± - ê·œì¹™ ì ìš© ë³´ìž¥ + í˜¸ì¶œ ìµœì†Œí™”."""
    current_kg = _get_kg()
    current_pipeline = _get_pipeline()

    # Phase 2-1: Normalize query type using QTYPE_MAP
    normalized_qtype = QTYPE_MAP.get(qtype, "explanation")
    logger.info(
        "Query type '%s' normalized to '%s' for rule loading",
        qtype,
        normalized_qtype,
    )

    query_intent = None
    max_chars: int | None = None

    if qtype == "target_short":
        query_intent = "ê°„ë‹¨í•œ ì‚¬ì‹¤ í™•ì¸ ì§ˆë¬¸"
        if previous_queries:
            prev_text = "\n".join(f"- {q}" for q in previous_queries if q)
            query_intent += f"""

[ì¤‘ë³µ ë°©ì§€]
ë‹¤ìŒ ì§ˆì˜ì—ì„œ ë‹¤ë£¬ ë‚´ìš©ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ êµ¬ì²´ì  íŒ©íŠ¸(ë‚ ì§œ, ìˆ˜ì¹˜, ëª…ì¹­ ë“±)ë¥¼ ì§ˆë¬¸í•˜ì„¸ìš”:
{prev_text}
"""
    elif qtype == "target_long":
        query_intent = "í•µì‹¬ ìš”ì ì„ ë¬»ëŠ” ì§ˆë¬¸"
        if previous_queries:
            prev_text = "\n".join(f"- {q}" for q in previous_queries if q)
            query_intent += f"""

[ì¤‘ë³µ ë°©ì§€]
ë‹¤ìŒ ì§ˆì˜ì™€ ë‹¤ë¥¸ ê´€ì /ì„¸ë¶€ í•­ëª©ì„ ë¬»ëŠ” ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”:
{prev_text}
"""
    elif qtype == "reasoning":
        query_intent = "ì¶”ë¡ /ì˜ˆì¸¡ ì§ˆë¬¸"
    elif qtype == "global_explanation":
        query_intent = "ì „ì²´ ë‚´ìš© ì„¤ëª… ì§ˆë¬¸"

    # ì¤‘ë³µ/ë³‘ë ¬ ì§ˆë¬¸ ë°©ì§€ ê³µí†µ ì§€ì‹œ
    single_focus_clause = """
[ë‹¨ì¼ í¬ì»¤ìŠ¤ í•„ìˆ˜]
- í•œ ê°€ì§€ ê³¼ì—…ë§Œ ì§ˆë¬¸ (ê·¼ê±°+ì „ë§ì²˜ëŸ¼ ë‘ í•­ëª©ì„ ë™ì‹œì— ë¬»ì§€ ë§ ê²ƒ)
- 'ì™€/ê³¼/ë°/ë˜ëŠ”'ìœ¼ë¡œ ì„œë¡œ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ë³‘ë ¬ ì—°ê²° ê¸ˆì§€
- í•„ìš”í•˜ë©´ í•œ í•­ëª©ë§Œ ë¬»ë„ë¡ ìž¬ìž‘ì„±
"""
    if query_intent:
        query_intent += single_focus_clause
    else:
        query_intent = single_focus_clause

    rule_loader = RuleLoader(current_kg)
    rules_list = rule_loader.get_rules_for_type(normalized_qtype, DEFAULT_ANSWER_RULES)
    query_constraints: list[dict[str, Any]] = []
    answer_constraints: list[dict[str, Any]] = []
    formatting_rules: list[str] = []
    unified_validator = UnifiedValidator(current_kg, current_pipeline)
    kg_wrapper: Any | None = get_cached_kg()

    if kg_wrapper is not None:
        try:
            # [Fix] Step 1: Enhanced type validation with detailed logging
            # Use normalized_qtype to ensure subtypes (e.g., target_short) get constraints from parent (target)
            constraints = kg_wrapper.get_constraints_for_query_type(normalized_qtype)

            if not isinstance(constraints, list):
                logger.error(
                    "ðŸ”´ Invalid constraints type from Neo4j: expected list, got %s. Value: %r",
                    type(constraints).__name__,
                    repr(constraints)[:100],
                )
                constraints = []

            # [Fix] Step 2: Validate each item is a dict with detailed logging
            valid_constraints = []
            invalid_items = []

            for c in constraints:
                if isinstance(c, dict):
                    valid_constraints.append(c)
                else:
                    invalid_items.append(
                        {"type": type(c).__name__, "value": repr(c)[:50]},
                    )

            if invalid_items:
                logger.error(
                    "ðŸ”´ Invalid constraint items dropped: %d/%d. Samples: %s",
                    len(invalid_items),
                    len(constraints),
                    str(invalid_items[:3])[:200],  # Limit log message size
                )

            # [Fix] Step 3: Safe category access with .get()
            query_constraints = [
                c for c in valid_constraints if c.get("category") in ["query", "both"]
            ]
            answer_constraints = [
                c for c in valid_constraints if c.get("category") in ["answer", "both"]
            ]

            # Success logging
            logger.info(
                "âœ… Constraints loaded: query=%d, answer=%d",
                len(query_constraints),
                len(answer_constraints),
            )
            # [Fix] Step 4: Enhanced formatting rules validation
            try:
                fmt_rules = kg_wrapper.get_formatting_rules_for_query_type(
                    normalized_qtype,
                )

                # Type validation with detailed logging
                if not isinstance(fmt_rules, list):
                    logger.error(
                        "ðŸ”´ Invalid formatting rules type: expected list, got %s",
                        type(fmt_rules).__name__,
                    )
                    fmt_rules = []

                # Validate each rule is a dict
                valid_fmt_rules = []
                for fr in fmt_rules:
                    if isinstance(fr, dict):
                        desc = fr.get("description") or fr.get("text")
                        if desc:
                            formatting_rules.append(desc)
                            valid_fmt_rules.append(fr)
                    else:
                        logger.warning(
                            "Invalid formatting rule (not dict): %s",
                            type(fr).__name__,
                        )

                logger.info("âœ… Formatting rules loaded: %d", len(formatting_rules))
            except Exception as e:  # noqa: BLE001
                logger.debug("ì„œì‹ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: %s", e)

            logger.info(
                "%s íƒ€ìž…: ì§ˆì˜ ì œì•½ %sê°œ, ë‹µë³€ ì œì•½ %sê°œ ì¡°íšŒ",
                qtype,
                len(query_constraints),
                len(answer_constraints),
            )
        except Exception as e:
            logger.warning("ê·œì¹™ ì¡°íšŒ ì‹¤íŒ¨: %s", e)

    # ì§ˆì˜ ì¤‘ë³µ/ë³µí•© ë°©ì§€ìš© ê³µí†µ ì œì•½ ì¶”ê°€
    query_constraints.append(
        {
            "description": "ë‹¨ì¼ ê³¼ì—…ë§Œ ë¬»ê¸°: 'ì™€/ê³¼/ë°/ë˜ëŠ”'ìœ¼ë¡œ ë³‘ë ¬ ì§ˆë¬¸(ë‘ ê°€ì§€ ì´ìƒ ìš”êµ¬) ê¸ˆì§€",
            "priority": 100,
            "category": "query",
        },
    )

    if not rules_list:
        rules_list = list(DEFAULT_ANSWER_RULES)
        logger.info("Neo4j ê·œì¹™ ì—†ìŒ, ê¸°ë³¸ ê·œì¹™ ì‚¬ìš©")

    extra_instructions = "ì§ˆì˜ ìœ í˜•ì— ë§žê²Œ ìž‘ì„±í•˜ì„¸ìš”."
    length_constraint = ""
    if normalized_qtype == "reasoning":
        extra_instructions = """ì¶”ë¡ í˜• ë‹µë³€ìž…ë‹ˆë‹¤.
[í•„ìˆ˜ êµ¬ì¡° - ì§ˆì˜ë‹µë³€ì˜ˆì‹œ.txt í˜•ì‹]
1. ì²« ì¤„: **êµµì€ ì œëª©** (í•µì‹¬ ì „ë§/ê²°ë¡ ì„ í•œ ë¬¸ìž¥ìœ¼ë¡œ)
2. ë³¸ë¬¸: ë¶ˆë¦¿ í¬ì¸íŠ¸(-)ë¡œ ê·¼ê±°ì™€ ì¶”ë¡  ë‚˜ì—´
3. ë§ˆì§€ë§‰ ë¬¸ìž¥: ì¢…í•©ì  ê²°ë¡ 

[ì˜ˆì‹œ í˜•ì‹]
**ê³ ìš© ì‹œìž¥ ì „ë§ ì•…í™”ë¡œ ê¸ˆë¦¬ ì¸í•˜ ì•žë‹¹ê²¨ì§ˆ ê°€ëŠ¥ì„±**
- ì²« ë²ˆì§¸ ê·¼ê±° ì„¤ëª…
- ë‘ ë²ˆì§¸ ê·¼ê±° ì„¤ëª…
- ê²°ë¡ ì ìœ¼ë¡œ ~í•  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.

[ê¸ˆì§€ ì‚¬í•­]
- 'ê·¼ê±°', 'ì¶”ë¡  ê³¼ì •', 'ê²°ë¡ ' ë“± ëª…ì‹œì  ë¼ë²¨ ê¸ˆì§€
- ë¶ˆí•„ìš”í•œ ì„œë¡  ê¸ˆì§€ (ë°”ë¡œ í•µì‹¬ìœ¼ë¡œ)
- ìž¥í™©í•œ ì„¤ëª… ê¸ˆì§€"""
        length_constraint = """
[CRITICAL - ê¸¸ì´ ì œì•½]
**ì ˆëŒ€ ê·œì¹™**: ì´ ì‘ë‹µì€ ìµœëŒ€ 200ë‹¨ì–´, 3-5ê°œ ë¶ˆë¦¿ í¬ì¸íŠ¸ì˜ ê°„ê²°í•œ ì¶”ë¡ ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- êµµì€ ì œëª© 1ì¤„ + ë¶ˆë¦¿ í¬ì¸íŠ¸ 3-5ê°œ
- ê° ë¶ˆë¦¿ì€ 1-2ë¬¸ìž¥
- ìµœëŒ€ 200ë‹¨ì–´ ì´ˆê³¼ ê¸ˆì§€
"""
    elif normalized_qtype == "explanation":
        # Few-Shot: Load examples from Neo4j for better length adherence
        fewshot_text = ""
        try:
            fewshot_examples: list[dict[str, Any]] = []
            if current_kg is not None:
                example_selector = DynamicExampleSelector(current_kg)
                fewshot_examples = example_selector.select_best_examples(
                    "explanation", {}, k=1
                )
            if fewshot_examples:
                ex = fewshot_examples[0]
                ex_text = ex.get("example", "")[:1500]  # Truncate if too long
                fewshot_text = f"""
[ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ - ì´ ê¸¸ì´ì™€ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì„¸ìš”]
{ex_text}
---
ìœ„ ì˜ˆì‹œì²˜ëŸ¼ **ì¶©ë¶„í•œ ê¸¸ì´ì™€ êµ¬ì¡°**ë¡œ ìž‘ì„±í•˜ì„¸ìš”.
"""
                logger.info("Few-Shot example loaded: %d chars", len(ex_text))
        except Exception as e:
            logger.debug("Few-shot loading failed: %s", e)

        extra_instructions = f"""ì„¤ëª…í˜• ë‹µë³€ìž…ë‹ˆë‹¤.
[í•„ìˆ˜ êµ¬ì¡°]
1. ì²« ì¤„: **êµµì€ ì œëª©** (í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ìž¥ìœ¼ë¡œ)
2. ë„ìž…: 1-2ë¬¸ìž¥ìœ¼ë¡œ ì „ì²´ ë§¥ë½ ìš”ì•½
3. ë³¸ë¬¸: ë¶ˆë¦¿ í¬ì¸íŠ¸(-)ë¡œ ì£¼ìš” ìš”ì¸ ë‚˜ì—´ (ìµœì†Œ 5ê°œ)
4. ê²°ë¡ : ë§ˆì§€ë§‰ ë¬¸ìž¥ìœ¼ë¡œ ì¢…í•©

{fewshot_text}

[ê¸ˆì§€ ì‚¬í•­]
- 'ì„œë¡ ', 'ë³¸ë¡ ', 'ê²°ë¡ ' ë“± ë¼ë²¨ ê¸ˆì§€
- ë¶ˆí•„ìš”í•œ ë°˜ë³µ, ìž¥í™©í•œ ìˆ˜ì‹ì–´ ê¸ˆì§€"""

        # Dynamic length calculation (60-80% of OCR length)
        ocr_len = len(ocr_text)
        min_chars = int(ocr_len * 0.6)
        max_chars = int(ocr_len * 0.8)

        length_constraint = f"""
[CRITICAL - ê¸¸ì´ ì œì•½]
**ì ˆëŒ€ ê·œì¹™**: ì´ ì‘ë‹µì€ OCR ì›ë¬¸ ê¸¸ì´({ocr_len}ìž)ì— ë¹„ë¡€í•˜ì—¬ **ìµœì†Œ {min_chars}ìž ~ ìµœëŒ€ {max_chars}ìž** ë¶„ëŸ‰ìž…ë‹ˆë‹¤.
- 5-8ê°œ ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±
- êµµì€ ì œëª© 1ì¤„ + ë„ìž… 1-2ë¬¸ìž¥ + ë¶ˆë¦¿ 5ê°œ ì´ìƒ + ê²°ë¡ 
- ê° ë¶ˆë¦¿ì€ 1-2ë¬¸ìž¥
- í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ë¹ ì§ì—†ì´ ë‹¤ë£° ê²ƒ
âŒ {min_chars}ìž ë¯¸ë§Œ = ì‹¤íŒ¨ (ë°˜ë“œì‹œ ê¸¸ì´ ì¤€ìˆ˜)
"""
    elif normalized_qtype == "target":
        if qtype == "target_short":
            extra_instructions = """
âš ï¸ ì¤‘ìš”: ë°˜ë“œì‹œ 1-2ë¬¸ìž¥ë§Œ ìž‘ì„±. 3ë¬¸ìž¥ ì´ìƒ ìž‘ì„±í•˜ë©´ ì‹¤íŒ¨ìž…ë‹ˆë‹¤.
- ëª…í™•í•˜ê³  ê°„ê²°í•œ ì‚¬ì‹¤ ì „ë‹¬
- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ë°°ì œ
- êµ¬ì²´ì  ìˆ˜ì¹˜ë‚˜ ë°ì´í„° í¬í•¨
âŒ ë³¼ë“œì²´(**) ì‚¬ìš© ê¸ˆì§€ - ì¤„ê¸€í˜• ë‹µë³€ì—ëŠ” **ì—†ì´** ìž‘ì„±
"""
            length_constraint = """
[CRITICAL - ê¸¸ì´ ì œì•½ âš ï¸ ê°€ìž¥ ì¤‘ìš”]
1-2ë¬¸ìž¥, 50-150ìžë§Œ ìž‘ì„±í•˜ì„¸ìš”.
âŒ 3ë¬¸ìž¥ ì´ìƒ = ì‹¤íŒ¨
âŒ 150ìž ì´ˆê³¼ = ì‹¤íŒ¨
âŒ ë°°ê²½ ì„¤ëª… = ì‹¤íŒ¨
âŒ ë³¼ë“œì²´(**) ì‚¬ìš© = ì‹¤íŒ¨
âœ… í•µì‹¬ ì‚¬ì‹¤ë§Œ 1-2ë¬¸ìž¥ìœ¼ë¡œ, ë§ˆí¬ë‹¤ìš´ ì—†ì´ ë‹µë³€
"""
            rules_list = rules_list[:3]
        elif qtype == "target_long":
            extra_instructions = """
- OCR ì›ë¬¸ì˜ íŠ¹ì • ë‚´ìš©ì— ì§‘ì¤‘í•˜ì—¬ ì„œìˆ 
- í•µì‹¬ ë§¥ë½ê³¼ í•¨ê»˜ ê°„ê²°í•˜ê²Œ ë‹µë³€
- ë¶ˆí•„ìš”í•œ ë°°ê²½ ì„¤ëª… ìµœì†Œí™”
âŒ ë³¼ë“œì²´(**) ì‚¬ìš© ê¸ˆì§€ - ì¤„ê¸€í˜• ë‹µë³€ì—ëŠ” **ì—†ì´** ìž‘ì„±
"""
            length_constraint = """
[CRITICAL - ê¸¸ì´ ì œì•½]
200-400ìž, 3-4ë¬¸ìž¥ì˜ ê°„ê²°í•œ ì„œìˆ í˜• ë‹µë³€ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ì •í™•ížˆ 3-4ê°œ ë¬¸ìž¥ìœ¼ë¡œ êµ¬ì„±
- ê° ë¬¸ìž¥ì€ 50-100ìž ì •ë„
- í•µì‹¬ ë‚´ìš©ë§Œ í¬í•¨, ìž¥í™©í•œ ì„¤ëª… ê¸ˆì§€
- ë¬¸ë‹¨ êµ¬ë¶„ ì—†ì´ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ìž‘ì„±
âŒ ë³¼ë“œì²´(**) ì‚¬ìš© ê¸ˆì§€ - ë§ˆí¬ë‹¤ìš´ ì—†ì´ í‰ë¬¸ìœ¼ë¡œ ìž‘ì„±
"""
            rules_list = rules_list[:5]

    # PHASE 2B: Check cache before expensive operations to save ~6-12s
    # Use truncated OCR for cache key (QA_CACHE_OCR_TRUNCATE_LENGTH)
    cache_ocr_key = ocr_text[:QA_CACHE_OCR_TRUNCATE_LENGTH]

    try:
        # First, try to generate the query
        queries = await agent.generate_query(
            ocr_text,
            user_intent=query_intent,
            query_type=qtype,
            kg=kg_wrapper or current_kg,
            constraints=query_constraints,
        )
        if not queries:
            raise ValueError("ì§ˆì˜ ìƒì„± ì‹¤íŒ¨")

        query = queries[0]

        # PHASE 2B: Enhanced cache logging for debugging
        cache_key_hash = hashlib.sha256(
            f"{query}|{cache_ocr_key}|{qtype}".encode(),
        ).hexdigest()[:16]
        logger.info(
            "Cache Key Generated - "
            "Query length: %d | "
            "OCR: %d | "
            "Type: %s | "
            "Key hash: %s",
            len(query),
            len(cache_ocr_key),
            qtype,
            cache_key_hash,
        )

        # PHASE 2B: Check cache after query generation
        cached_result = await answer_cache.get(query, cache_ocr_key, qtype)
        if cached_result is not None:
            cache_stats = answer_cache.get_stats()
            logger.info(
                "âœ… CACHE HIT! Saved ~%d seconds. "
                "Query: %s... | "
                "Current cache size: %d | "
                "Hit rate: %.1f%%",
                ESTIMATED_CACHE_HIT_TIME_SAVINGS,
                query[:50],
                cache_stats["cache_size"],
                cache_stats["hit_rate_percent"],
            )
            return cast("dict[str, Any]", cached_result)

        cache_stats = answer_cache.get_stats()
        logger.info(
            "âŒ CACHE MISS - Will generate new answer. "
            "Current cache size: %d | "
            "Hit rate: %.1f%%",
            cache_stats["cache_size"],
            cache_stats["hit_rate_percent"],
        )

        truncated_ocr = ocr_text[:QA_GENERATION_OCR_TRUNCATE_LENGTH]
        rules_in_answer = "\n".join(f"- {r}" for r in rules_list)
        formatting_text = ""
        if formatting_rules:
            formatting_text = "\n[ì„œì‹ ê·œì¹™ - í•„ìˆ˜ ì¤€ìˆ˜]\n" + "\n".join(
                f"- {r}" for r in formatting_rules
            )

        # Add markdown usage policy based on qtype (Phase 1: IMPROVEMENTS.md)
        if normalized_qtype == "target":
            formatting_text += (
                "\n\n[ë§ˆí¬ë‹¤ìš´ ì‚¬ìš©]\n"
                "í‰ë¬¸ìœ¼ë¡œë§Œ ìž‘ì„±í•˜ì„¸ìš”. "
                "ë§ˆí¬ë‹¤ìš´(**bold**, *italic*, - ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. "
                "(â†’ í›„ì²˜ë¦¬ì—ì„œ ëª¨ë‘ ì œê±°ë©ë‹ˆë‹¤)"
            )
        elif normalized_qtype in {"explanation", "reasoning"}:
            formatting_text += (
                "\n\n[ë§ˆí¬ë‹¤ìš´ ì‚¬ìš© ê·œì¹™ - í•„ìˆ˜ ì¤€ìˆ˜]\n"
                "âœ… í—ˆìš©ë˜ëŠ” ë§ˆí¬ë‹¤ìš´:\n"
                "  - **bold**: í•µì‹¬ í‚¤ì›Œë“œ ê°•ì¡°ìš© (ì˜ˆ: **ì£¼ìš” í¬ì¸íŠ¸**)\n"
                "  - 1. 2. 3.: ìˆœì„œê°€ ìžˆëŠ” ëª©ë¡\n"
                "  - - í•­ëª©: ìˆœì„œê°€ ì—†ëŠ” ë¶ˆë¦¿ í¬ì¸íŠ¸\n"
                "\n"
                "âŒ ì‚¬ìš© ê¸ˆì§€ ë§ˆí¬ë‹¤ìš´:\n"
                "  - *italic*: ê°€ë…ì„± ì €í•˜ (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€)\n"
                "  - ### ì œëª©: ë¶ˆí•„ìš”í•œ í—¤ë” (ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€)\n"
                "  - `ì½”ë“œ`: ì¼ë°˜ QAì— ë¶ˆí•„ìš”\n"
                "\n"
                "ì˜ˆì‹œ (ì˜¬ë°”ë¥¸ í˜•ì‹):\n"
                "**ë¯¸-ì¤‘ ê°ˆë“± ê³ ì¡° ë° íˆ¬ìž ì‹¬ë¦¬ ìœ„ì¶•**\n"
                "ì „ì¼ í•œêµ­ ì¦ì‹œëŠ” ì—¬ëŸ¬ ìš”ì¸ì´ ë³µí•©ì ìœ¼ë¡œ ìž‘ìš©...\n"
                "- ì²« ë²ˆì§¸ ìš”ì¸: ì„¤ëª…\n"
                "- ë‘ ë²ˆì§¸ ìš”ì¸: ì„¤ëª…\n"
            )

        constraints_text = ""
        if answer_constraints:

            def _priority_value(item: dict[str, Any]) -> float:
                val = item.get("priority")
                return float(val) if isinstance(val, (int, float)) else 0.0

            answer_constraints.sort(key=_priority_value, reverse=True)
            constraints_text = "\n".join(
                f"[ìš°ì„ ìˆœìœ„ {c.get('priority', 0)}] {c.get('description', '')}"
                for c in answer_constraints
            )

            # Phase 3: Validate constraint conflicts (IMPROVEMENTS.md)
            # Extract max_length from length_constraint if present
            max_length_val: int | None = None
            if "50ë‹¨ì–´" in length_constraint:
                max_length_val = 50
            elif "100ë‹¨ì–´" in length_constraint:
                max_length_val = 100
            elif "200ë‹¨ì–´" in length_constraint:
                max_length_val = 200
            elif "300ë‹¨ì–´" in length_constraint:
                max_length_val = 300

            # Check for paragraph constraints in answer_constraints
            # Note: This is a heuristic parser for constraint descriptions.
            # Expected format: "Xë¬¸ë‹¨, ê° Yë‹¨ì–´ ì´ìƒ" or similar
            min_per_para: int | None = None
            num_paras: int | None = None
            for constraint in answer_constraints:
                desc = constraint.get("description", "").lower()
                if "ë¬¸ë‹¨" in desc and "ë‹¨ì–´" in desc:
                    # Try to extract numbers from constraint description
                    numbers = re.findall(r"\d+", desc)
                    if len(numbers) >= 2:
                        # Heuristic: first number might be paragraph count, second might be words
                        try:
                            if "ê°" in desc or "ë‹¹" in desc:
                                num_paras = int(numbers[0])
                                min_per_para = int(numbers[1])
                        except (ValueError, IndexError):
                            pass

            if max_length_val:
                is_valid, validation_msg = validate_constraints(
                    qtype=normalized_qtype,
                    max_length=max_length_val,
                    min_per_paragraph=min_per_para,
                    num_paragraphs=num_paras,
                )
                if not is_valid:
                    logger.warning(
                        "âš ï¸ ì œì•½ ì¶©ëŒ ê°ì§€: %s (qtype=%s)",
                        validation_msg,
                        normalized_qtype,
                    )

        difficulty_text = _difficulty_hint(ocr_text)
        evidence_clause = "ìˆ«ìžÂ·ê³ ìœ ëª…ì‚¬ëŠ” OCRì— ë‚˜ì˜¨ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ , ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ìž¥ì„ 1ê°œ í¬í•¨í•˜ì„¸ìš”."

        # Phase 2: Add explicit priority hierarchy and conflict resolution (IMPROVEMENTS.md)
        markdown_rule = (
            "í‰ë¬¸ë§Œ (ë§ˆí¬ë‹¤ìš´ ì œê±°)"
            if normalized_qtype == "target"
            else "êµ¬ì¡°ë§Œ ë§ˆí¬ë‹¤ìš´(ì œëª©/ëª©ë¡), ë‚´ìš©ì€ í‰ë¬¸"
        )
        max_length_text = ""
        if "ìµœëŒ€ 50ë‹¨ì–´" in length_constraint:
            max_length_text = "50ë‹¨ì–´"
        elif "ìµœëŒ€ 100ë‹¨ì–´" in length_constraint:
            max_length_text = "100ë‹¨ì–´"
        elif "200ë‹¨ì–´" in length_constraint:
            max_length_text = "200ë‹¨ì–´"
        else:
            max_length_text = "[MAX_LENGTH]ë‹¨ì–´"

        priority_hierarchy = f"""
[PRIORITY HIERARCHY]
Priority 0 (CRITICAL):
- {normalized_qtype} íƒ€ìž…: {markdown_rule}

Priority 10 (HIGH):
- ìµœëŒ€ ê¸¸ì´: {max_length_text} ì´ë‚´
- ê¸¸ì´ ì œì•½ ìœ„ë°˜ì€ ë¶ˆê°€ëŠ¥

Priority 20 (MEDIUM):
- êµ¬ì¡°í™” í˜•ì‹: {formatting_text if formatting_text else "ê¸°ë³¸ ì„œì‹"}

Priority 30 (LOW):
- ì¶”ê°€ ì§€ì‹œ: {extra_instructions}

[CONFLICT RESOLUTION]
ë§Œì•½ ì—¬ëŸ¬ ì œì•½ì´ ì¶©ëŒí•œë‹¤ë©´:
â†’ Priority 0 > Priority 10 > Priority 20 > Priority 30

[REASONING BEFORE RESPONSE]
ì‘ë‹µí•˜ê¸° ì „ì— ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
1. í˜„ìž¬ qtypeì€ ë¬´ì—‡ì¸ê°€? â†’ ì˜¬ë°”ë¥¸ ë§ˆí¬ë‹¤ìš´ ê·œì¹™ í™•ì¸ (Priority 0)
2. ê¸¸ì´ ì œì•½ì€ ëª‡ ë‹¨ì–´ì¸ê°€? â†’ {max_length_text} ì´ë‚´ ìœ ì§€ (Priority 10)
3. êµ¬ì¡°í™” ë°©ì‹ì€? â†’ formatting_text ê·œì¹™ ì ìš© (Priority 20)
4. ì¶”ê°€ ìš”ì²­ì‚¬í•­ì€? â†’ extra_instructions ì¶”ê°€ ì²˜ë¦¬ (Priority 30)
"""

        answer_prompt = f"""{priority_hierarchy}

{length_constraint}

{formatting_text}

[ì œì•½ì‚¬í•­]
{constraints_text or rules_in_answer}

[ì§ˆì˜]: {query}

[OCR í…ìŠ¤íŠ¸]
{truncated_ocr}

ìœ„ ê¸¸ì´/í˜•ì‹ ì œì•½ê³¼ ê·œì¹™ì„ ì—„ê²©ížˆ ì¤€ìˆ˜í•˜ì—¬ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
{difficulty_text}
{evidence_clause}
{extra_instructions}"""

        draft_answer = await agent.rewrite_best_answer(
            ocr_text=ocr_text,
            best_answer=answer_prompt,
            cached_content=None,
            query_type=normalized_qtype,
            kg=kg_wrapper or current_kg,
            constraints=answer_constraints,
            length_constraint=length_constraint,
        )
        if not draft_answer:
            raise SafetyFilterError("No text content in response.")

        # Enhanced logging for answer length debugging (Fix #3)
        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(
                "Answer length tracking - qtype=%s, OCR=%d chars, draft=%d chars",
                qtype,
                len(ocr_text),
                len(draft_answer),
            )

        # í†µí•© ê²€ì¦ìœ¼ë¡œ ìˆ˜ì§‘í•  ìœ„ë°˜/ê²½ê³  (ì§ˆì˜ í¬í•¨í•˜ì—¬ ê¸ˆì§€ íŒ¨í„´ ê²€ì¦ ê°•í™”)
        val_result = unified_validator.validate_all(
            draft_answer,
            normalized_qtype,
            query,
        )
        all_issues: list[str] = []

        sentences = [
            s
            for s in draft_answer.replace("?", ".").replace("!", ".").split(".")
            if s.strip()
        ]
        sentence_count = len(sentences)
        # target_shortë§Œ ë¬¸ìž¥ ìˆ˜ ì œí•œ (1-2ë¬¸ìž¥), ë‚˜ë¨¸ì§€ íƒ€ìž…ì€ ê²€ì¦ skip
        if qtype == "target_short" and sentence_count > 2:
            all_issues.append(f"1-2ë¬¸ìž¥ìœ¼ë¡œ ì¶•ì†Œ í•„ìš” (í˜„ìž¬ {sentence_count}ë¬¸ìž¥)")

        all_violations: list[str] = []
        if normalized_qtype == "reasoning" and (
            "ìš”ì•½ë¬¸" in draft_answer or "ìš”ì•½" in draft_answer.splitlines()[0]
        ):
            all_violations.append("summary_header_not_allowed")

        # Explicit rule compliance check when KG is available (for tests/validation)
        if kg_wrapper is not None:
            try:
                validator_cls = _get_validator_class()
                validator = validator_cls(kg_wrapper)
                rule_check = validator._check_rule_compliance(
                    draft_answer,
                    normalized_qtype,
                )
                score = rule_check.get("score")
                score_val = score if isinstance(score, (int, float)) else 1.0
                if rule_check.get("violations") and score_val < 0.3:
                    all_violations.extend(rule_check.get("violations", []))
            except Exception:
                pass

        # ê¸°ì¡´ íƒì§€ + í†µí•© ê²€ì¦ ë³‘í•©
        violations = find_violations(draft_answer)
        if violations:
            for v in violations:
                v_type = v["type"]
                # NOTE: ì‹œì˜ì„± í‘œí˜„ì€ ì¸ê°„ ìž‘ì—…ìžê°€ ìµœì¢… ìˆ˜ì • ì˜ˆì •ì´ë¯€ë¡œ ê²€ì¦ ì œì™¸
                if v_type.startswith("error_pattern:ì‹œì˜ì„±"):
                    continue
                if "temporal" in v_type.lower():
                    continue  # ì‹œì˜ì„± ê´€ë ¨ ëª¨ë“  íŒ¨í„´ ì œì™¸
                all_violations.append(v_type)

        formatting_violations = find_formatting_violations(draft_answer)
        for fv in formatting_violations:
            if fv.get("severity") == "error":
                all_violations.append(fv["type"])
                logger.warning(
                    "ì„œì‹ ìœ„ë°˜ ê°ì§€: %s - '%s'",
                    fv.get("description", ""),
                    fv["match"],
                )

        if current_pipeline is not None:
            validation = current_pipeline.validate_output(
                normalized_qtype,
                draft_answer,
            )
            if not validation.get("valid", True):
                all_violations.extend(validation.get("violations", []))
            missing_rules = validation.get("missing_rules_hint", [])
            if missing_rules:
                logger.debug("ëˆ„ë½ ê°€ëŠ¥ì„± ìžˆëŠ” ê·œì¹™: %s", missing_rules)

        if val_result.has_errors():
            all_violations.extend(
                [v.get("type", "rule") for v in val_result.violations],
            )
        if val_result.warnings:
            all_issues.extend(val_result.warnings)

        # ì‹œì˜ì„± ê´€ë ¨ ìœ„ë°˜ í•„í„°ë§ (ì¸ê°„ ìž‘ì—…ìžê°€ ìµœì¢… ìˆ˜ì • ì˜ˆì •)
        all_violations = [
            v
            for v in all_violations
            if "ì‹œì˜ì„±" not in v and "temporal" not in v.lower()
        ]

        if all_violations:
            all_issues.extend(all_violations[:3])

        if all_issues:
            combined_request = "; ".join(all_issues)
            logger.warning("ê²€ì¦ ì‹¤íŒ¨, ìž¬ìƒì„± ì‹œë„: %s", combined_request)
            try:
                rewritten = await agent.rewrite_best_answer(
                    ocr_text=ocr_text,
                    best_answer=draft_answer,
                    edit_request=f"ë‹¤ìŒ ì‚¬í•­ ìˆ˜ì •: {combined_request}",
                    cached_content=None,
                    constraints=answer_constraints,
                    length_constraint=length_constraint,
                )
                # ë¹ˆ ì‘ë‹µì´ë©´ ì›ë³¸ ìœ ì§€
                if rewritten and rewritten.strip():
                    draft_answer = rewritten
                else:
                    logger.warning("ìž¬ìƒì„± ë¹ˆ ì‘ë‹µ, ì›ë³¸ ë‹µë³€ ì‚¬ìš©")
            except Exception as e:
                # ìž¬ìƒì„± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë‹µë³€ ì‚¬ìš© (Gemini API ì¼ì‹œ ì˜¤ë¥˜ ëŒ€ì‘)
                logger.warning("ìž¬ìƒì„± ì‹¤íŒ¨, ì›ë³¸ ë‹µë³€ ì‚¬ìš©: %s", str(e)[:100])

        final_answer = postprocess_answer(draft_answer, qtype, max_length=max_chars)

        # Enhanced logging: track length changes through post-processing (Fix #3)
        if normalized_qtype == "explanation":
            logger.info(
                "Answer length - OCR: %d chars | Draft: %d chars | Final: %d chars | Query: %s",
                len(ocr_text),
                len(draft_answer),
                len(final_answer),
                query[:50],
            )

        # Validate answer length for explanation type
        if normalized_qtype == "explanation":
            answer_length = len(final_answer)
            # Use dynamic min_chars (60% of OCR length) instead of hardcoded value
            if answer_length < min_chars:
                logger.warning(
                    "âš ï¸ Answer too short for explanation type: "
                    "%d chars (expected %d+, OCR %d chars). "
                    "Query: %s",
                    answer_length,
                    min_chars,
                    len(ocr_text),
                    query[:50],
                )

        # PHASE 2B: Store result in cache for future requests
        result = {"type": qtype, "query": query, "answer": final_answer}
        await answer_cache.set(query, cache_ocr_key, qtype, result)
        logger.debug("Cached answer for query_type=%s", qtype)

        return result
    except Exception as e:
        logger.error("QA ìƒì„± ì‹¤íŒ¨: %s", e)
        raise
