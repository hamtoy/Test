"""ë¡œê·¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹°

êµ¬ì¡°í™”ëœ ë¡œê·¸ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ API í˜¸ì¶œ íŒ¨í„´ ë° í†µê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import argparse
import json
import sys
from collections import Counter
from pathlib import Path
from typing import Any


def analyze_api_calls(log_file: Path) -> None:
    """API í˜¸ì¶œ íŒ¨í„´ ë¶„ì„"""
    calls: list[dict[str, Any]] = []

    with open(log_file, encoding="utf-8") as f:
        for line in f:
            if "api_call" in line:
                try:
                    data = json.loads(line)
                    calls.append(data)
                except json.JSONDecodeError:
                    continue

    if not calls:
        print("API í˜¸ì¶œ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í†µê³„
    total_calls = len(calls)
    latencies = [c.get("latency_ms", 0) for c in calls if "latency_ms" in c]
    avg_latency = sum(latencies) / len(latencies) if latencies else 0

    errors = sum(1 for c in calls if c.get("status") != "success")
    error_rate = errors / total_calls if total_calls else 0

    print("=" * 60)
    print("ğŸ“Š API í˜¸ì¶œ ë¶„ì„")
    print("=" * 60)
    print(f"ì´ í˜¸ì¶œ: {total_calls}")
    print(f"í‰ê·  ë ˆì´í„´ì‹œ: {avg_latency:.2f}ms")
    print(f"ì—ëŸ¬ìœ¨: {error_rate * 100:.2f}%")

    # ëª¨ë¸ë³„ í†µê³„
    models = Counter(c.get("model", "unknown") for c in calls)
    if models:
        print("\nğŸ“ˆ ëª¨ë¸ë³„ í˜¸ì¶œ ìˆ˜:")
        for model, count in models.most_common():
            print(f"  {model}: {count}")


def analyze_cache_events(log_file: Path) -> None:
    """ìºì‹œ ì´ë²¤íŠ¸ ë¶„ì„"""
    events: list[dict[str, Any]] = []

    with open(log_file, encoding="utf-8") as f:
        for line in f:
            if "cache" in line.lower():
                try:
                    data = json.loads(line)
                    if data.get("event_type") == "cache":
                        events.append(data)
                except json.JSONDecodeError:
                    continue

    if not events:
        print("ìºì‹œ ì´ë²¤íŠ¸ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    hits = sum(1 for e in events if e.get("hit"))
    misses = len(events) - hits
    hit_rate = hits / len(events) if events else 0

    print("=" * 60)
    print("ğŸ“Š ìºì‹œ ë¶„ì„")
    print("=" * 60)
    print(f"ì´ ì´ë²¤íŠ¸: {len(events)}")
    print(f"íˆíŠ¸: {hits}")
    print(f"ë¯¸ìŠ¤: {misses}")
    print(f"íˆíŠ¸ìœ¨: {hit_rate * 100:.2f}%")


def analyze_errors(log_file: Path) -> None:
    """ì—ëŸ¬ ë¡œê·¸ ë¶„ì„"""
    errors: list[str] = []

    with open(log_file, encoding="utf-8") as f:
        for line in f:
            if "ERROR" in line or '"level":"ERROR"' in line.lower():
                errors.append(line.strip())

    print("=" * 60)
    print("âŒ ì—ëŸ¬ ë¡œê·¸")
    print("=" * 60)
    print(f"ì´ ì—ëŸ¬: {len(errors)}")

    if errors:
        print("\nìµœê·¼ ì—ëŸ¬ (ë§ˆì§€ë§‰ 10ê°œ):")
        for error in errors[-10:]:
            # ë„ˆë¬´ ê¸´ ì¤„ì€ ì˜ë¼ì„œ í‘œì‹œ
            display = error[:150] + "..." if len(error) > 150 else error
            print(f"  {display}")


def main() -> None:
    parser = argparse.ArgumentParser(description="ë¡œê·¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹°")
    parser.add_argument("log_file", type=Path, help="ë¶„ì„í•  ë¡œê·¸ íŒŒì¼")
    parser.add_argument(
        "--type",
        choices=["api", "cache", "errors", "all"],
        default="all",
        help="ë¶„ì„ ìœ í˜• (default: all)",
    )

    args = parser.parse_args()

    if not args.log_file.exists():
        print(f"Error: ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.log_file}")
        sys.exit(1)

    if args.type in ("api", "all"):
        analyze_api_calls(args.log_file)
        print()

    if args.type in ("cache", "all"):
        analyze_cache_events(args.log_file)
        print()

    if args.type in ("errors", "all"):
        analyze_errors(args.log_file)


if __name__ == "__main__":
    main()
