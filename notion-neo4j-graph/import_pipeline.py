import logging
import os
import re
from contextlib import contextmanager
from typing import Any, Dict, List

from dotenv import load_dotenv
from neo4j import GraphDatabase, Session
from notion_client import Client

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("NotionNeo4jPipeline")

load_dotenv()


class DataValidator:
    """ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ í—¬í¼."""

    @staticmethod
    def validate_block(block: Dict[str, Any]) -> bool:
        """ë¸”ë¡ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦."""
        if not isinstance(block, dict):
            return False
        return not ("id" not in block or "type" not in block)


class NotionExtractor:
    """Notion ë°ì´í„° ì¶”ì¶œ í´ë˜ìŠ¤."""

    def __init__(self, token: str):
        """Notion í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”."""
        self.client = Client(auth=token)

    def get_page(self, page_id: str) -> Dict[str, Any]:
        """í˜ì´ì§€ ë©”íƒ€ë°ì´í„° ì¡°íšŒ."""
        try:
            return self.client.pages.retrieve(page_id)
        except Exception as e:
            logger.error(f"í˜ì´ì§€ ì¡°íšŒ ì‹¤íŒ¨ ({page_id}): {e}")
            return {}

    def get_blocks(self, block_id: str) -> List[Dict[str, Any]]:
        """ë¸”ë¡ì˜ ìì‹ ë¸”ë¡ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ì¡°íšŒ (ì „ì²´ íŠ¸ë¦¬)."""
        blocks = []
        cursor = None

        try:
            while True:
                response = self.client.blocks.children.list(
                    block_id=block_id, start_cursor=cursor
                )
                results = response.get("results", [])

                for block in results:
                    # ìì‹ì´ ìˆëŠ” ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì¡°íšŒ
                    if block.get("has_children"):
                        children = self.get_blocks(block["id"])
                        block["children"] = children
                    blocks.append(block)

                if not response.get("has_more"):
                    break
                cursor = response.get("next_cursor")

        except Exception as e:
            logger.error(f"ë¸”ë¡ ì¡°íšŒ ì‹¤íŒ¨ ({block_id}): {e}")

        return blocks


class Neo4jAuraImporter:
    """Neo4j Aura ìµœì í™” ì„í¬í„°."""

    # í•˜ì´í”ˆ + ëŒ€ë¬¸ì í—ˆìš© Notion URL íŒ¨í„´
    NOTION_URL_PATTERN = (
        r"https?://(?:www\.)?notion\.so/[^/\s]+/"
        r"([A-Fa-f0-9]{8}-?[A-Fa-f0-9]{4}-?[A-Fa-f0-9]{4}-?[A-Fa-f0-9]{4}-?[A-Fa-f0-9]{12})"
    )

    BATCH_SIZE = 100
    REFERENCE_BATCH_SIZE = 500

    def __init__(self, uri: str, auth: tuple):
        """Neo4j ë“œë¼ì´ë²„ ì´ˆê¸°í™” ë° ì—°ê²° í™•ì¸."""
        self.driver = GraphDatabase.driver(uri, auth=auth)
        self.verify_connection()

    def close(self):
        """Neo4j ë“œë¼ì´ë²„ ì—°ê²° ì¢…ë£Œ."""
        self.driver.close()

    def verify_connection(self):
        """Neo4j ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸."""
        try:
            self.driver.verify_connectivity()
            logger.info("âœ… Neo4j ì—°ê²° í™•ì¸ë¨")
        except Exception as e:
            logger.error(f"âŒ Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    @contextmanager
    def session_context(self):
        """Neo4j ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €."""
        session = self.driver.session()
        try:
            yield session
        finally:
            session.close()

    def clear_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì£¼ì˜: ëª¨ë“  ë°ì´í„° ì‚­ì œ)."""
        logger.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        with self.session_context() as session:
            session.run("MATCH (n) DETACH DELETE n")
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

    def create_constraints(self):
        """ì¸ë±ìŠ¤ ë° ì œì•½ì¡°ê±´ ìƒì„±."""
        queries = [
            "CREATE CONSTRAINT page_id IF NOT EXISTS FOR (p:Page) REQUIRE p.id IS UNIQUE",
            "CREATE CONSTRAINT block_id IF NOT EXISTS FOR (b:Block) REQUIRE b.id IS UNIQUE",
            "CREATE INDEX block_content IF NOT EXISTS FOR (b:Block) ON (b.content)",
        ]
        with self.session_context() as session:
            for q in queries:
                session.run(q)
        logger.info("âœ… ì œì•½ì¡°ê±´ ë° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")

    def import_page(self, page_data: Dict[str, Any], blocks: List[Dict[str, Any]]):
        """í˜ì´ì§€ì™€ ë¸”ë¡ ì „ì²´ ì„í¬íŠ¸."""
        page_id = page_data["id"].replace("-", "")
        title = "Untitled"

        # ì œëª© ì¶”ì¶œ
        props = page_data.get("properties", {})
        title_prop = props.get("title") or props.get("Name")
        if title_prop and "title" in title_prop:
            title = "".join([t["plain_text"] for t in title_prop["title"]])

        url = page_data.get("url", "")

        logger.info(f"ğŸ“¥ í˜ì´ì§€ ì„í¬íŠ¸ ì‹œì‘: {title} ({page_id})")

        with self.session_context() as session:
            # 1. í˜ì´ì§€ ë…¸ë“œ ìƒì„±
            session.run(
                """
                MERGE (p:Page {id: $id})
                SET p.title = $title,
                    p.url = $url,
                    p.updated_at = datetime()
            """,
                id=page_id,
                title=title,
                url=url,
            )

            # 2. ë¸”ë¡ ì„í¬íŠ¸ (ë°˜ë³µì  ë°©ì‹)
            self._import_blocks_iterative(session, page_id, blocks)

    def _import_blocks_iterative(
        self, session: Session, page_id: str, blocks: List[Dict]
    ):
        # ì›ë³¸ ìˆœì„œ ìœ ì§€: orderëŠ” ì…ë ¥ ìˆœì„œ ê¸°ì¤€, ìŠ¤íƒ pushë§Œ ì—­ìˆœ
        top_level = [(idx, block) for idx, block in enumerate(blocks)]
        stack = [(block, None, None, 0, idx) for idx, block in reversed(top_level)]
        processed_blocks = []

        while stack:
            block, parent_id, prev_sibling_id, depth, order = stack.pop()

            if not DataValidator.validate_block(block):
                continue

            block_id = block["id"]

            # í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì¶”ì¶œ
            content = ""
            block_type = block["type"]
            if block_type in block and "rich_text" in block[block_type]:
                content = "".join(
                    [t["plain_text"] for t in block[block_type]["rich_text"]]
                )

            processed_blocks.append(
                {
                    "id": block_id,
                    "type": block_type,
                    "content": content,
                    "parent_id": parent_id,
                    "page_id": page_id if parent_id is None else None,
                    "prev_sibling_id": prev_sibling_id,
                    "depth": depth,
                    "order": order,
                }
            )

            if block.get("children"):
                children = block["children"]

                # ìœ íš¨í•œ ìì‹ë§Œ ì‚¬ìš©
                valid_children = [
                    (i, child)
                    for i, child in enumerate(children)
                    if isinstance(child, dict) and "id" in child
                ]

                # ì´ì „ í˜•ì œ ë§¤í•‘ (ìœ íš¨í•œ ìì‹ ê¸°ì¤€)
                prev_map = {}
                prev_valid_id = None
                for child_idx, child in valid_children:
                    prev_map[child_idx] = prev_valid_id
                    prev_valid_id = child.get("id")

                # ì—­ìˆœ pushë¡œ ì›ë˜ ìˆœì„œ pop
                for child_idx, child in reversed(valid_children):
                    stack.append(
                        (child, block_id, prev_map.get(child_idx), depth + 1, child_idx)
                    )

            if len(processed_blocks) >= self.BATCH_SIZE:
                self._batch_create_blocks(session, processed_blocks)
                processed_blocks = []

        if processed_blocks:
            self._batch_create_blocks(session, processed_blocks)

    def _batch_create_blocks(self, session: Session, blocks_data: List[Dict]):
        """ë¸”ë¡ ë°°ì¹˜ ìƒì„± ë° ê´€ê³„ ì„¤ì •."""
        query = """
        UNWIND $blocks AS block_data
        MERGE (b:Block {id: block_data.id})
        SET b.type = block_data.type,
            b.content = block_data.content,
            b.depth = block_data.depth,
            b.order = block_data.order
        
        // í˜ì´ì§€ ì—°ê²° (ìµœìƒìœ„ ë¸”ë¡ì¸ ê²½ìš°)
        WITH b, block_data
        CALL {
            WITH b, block_data
            WITH b, block_data
            WHERE block_data.page_id IS NOT NULL
            MATCH (p:Page {id: block_data.page_id})
            MERGE (p)-[:HAS_BLOCK]->(b)
        }
        
        // ë¶€ëª¨ ë¸”ë¡ ì—°ê²°
        CALL {
            WITH b, block_data
            WITH b, block_data
            WHERE block_data.parent_id IS NOT NULL
            MATCH (parent:Block {id: block_data.parent_id})
            MERGE (parent)-[:HAS_CHILD]->(b)
        }
        
        // ì´ì „ í˜•ì œ ì—°ê²° (ìˆœì„œ ë³´ì¥ìš©)
        CALL {
            WITH b, block_data
            WITH b, block_data
            WHERE block_data.prev_sibling_id IS NOT NULL
            MATCH (prev:Block {id: block_data.prev_sibling_id})
            MERGE (prev)-[:NEXT]->(b)
        }
        """
        session.run(query, blocks=blocks_data)

    def create_cross_references(self):
        """í˜ì´ì§€ ê°„ êµì°¨ ì°¸ì¡°(ë©˜ì…˜) ê´€ê³„ ìƒì„±."""
        pattern = re.compile(self.NOTION_URL_PATTERN)

        with self.session_context() as session:
            offset = 0
            total_refs = 0

            while True:
                result = session.run(
                    """
                    MATCH (b:Block)
                    WHERE b.content CONTAINS 'notion.so'
                    RETURN b.id AS block_id, b.content AS content
                    ORDER BY b.id
                    SKIP $offset
                    LIMIT $limit
                """,
                    offset=offset,
                    limit=self.REFERENCE_BATCH_SIZE,
                )

                records = list(result)
                if not records:
                    break

                references = []
                for record in records:
                    block_id = record["block_id"]
                    content = record["content"]

                    for page_id_raw in pattern.findall(content):
                        clean_id = page_id_raw.replace("-", "")
                        references.append({"block_id": block_id, "page_id": clean_id})

                if references:
                    session.execute_write(self._create_references_tx, references)
                    total_refs += len(references)

                offset += self.REFERENCE_BATCH_SIZE
                logger.info(f"   ì°¸ì¡° ì²˜ë¦¬ ì¤‘... ({offset}ê°œ ë¸”ë¡ ì™„ë£Œ)")

            logger.info(
                "âœ… êµì°¨ ì°¸ì¡° %dê°œ ìƒì„± ì™„ë£Œ" % total_refs
                if total_refs
                else "â„¹ï¸  êµì°¨ ì°¸ì¡° ì—†ìŒ"
            )

    @staticmethod
    def _create_references_tx(tx, references):
        query = """
        UNWIND $refs AS ref
        MATCH (b:Block {id: ref.block_id})
        MATCH (p:Page {id: ref.page_id})
        MERGE (b)-[:MENTIONS]->(p)
        """
        tx.run(query, refs=references)


def main():
    """Notion ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë° Neo4j ì €ì¥ ë©”ì¸ í•¨ìˆ˜."""
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    notion_token = os.environ.get("NOTION_TOKEN")
    page_ids_str = os.environ.get("NOTION_PAGE_IDS")
    neo4j_uri = os.environ.get("NEO4J_URI")
    neo4j_user = os.environ.get("NEO4J_USER", "neo4j")
    neo4j_password = os.environ.get("NEO4J_PASSWORD")

    if not all([notion_token, page_ids_str, neo4j_uri, neo4j_password]):
        logger.error("âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤ (.env í™•ì¸ í•„ìš”)")
        return

    page_ids = [pid.strip() for pid in page_ids_str.split(",") if pid.strip()]

    # ì´ˆê¸°í™”
    extractor = NotionExtractor(notion_token)
    importer = Neo4jAuraImporter(neo4j_uri, (neo4j_user, neo4j_password))

    try:
        # 1. DB ì´ˆê¸°í™” ë° ìŠ¤í‚¤ë§ˆ ì„¤ì •
        importer.clear_database()
        importer.create_constraints()

        # 2. í˜ì´ì§€ë³„ ë°ì´í„° ì¶”ì¶œ ë° ì„í¬íŠ¸
        for page_id in page_ids:
            logger.info(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {page_id}")

            # Notion ë°ì´í„° ì¶”ì¶œ
            page_data = extractor.get_page(page_id)
            if not page_data:
                continue

            blocks = extractor.get_blocks(page_id)
            logger.info(f"   - ë¸”ë¡ {len(blocks)}ê°œ ì¶”ì¶œ ì™„ë£Œ")

            # Neo4j ì„í¬íŠ¸
            importer.import_page(page_data, blocks)
            logger.info("   - Neo4j ì €ì¥ ì™„ë£Œ")

        # 3. êµì°¨ ì°¸ì¡° ìƒì„±
        logger.info("ğŸ”— êµì°¨ ì°¸ì¡°(Mentions) ì—°ê²° ì¤‘...")
        importer.create_cross_references()

        logger.info("ğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        importer.close()


if __name__ == "__main__":
    main()
