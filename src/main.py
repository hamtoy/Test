# -*- coding: utf-8 -*-
import os
import sys
import logging
import asyncio
import argparse
import json
from pathlib import Path
from typing import Dict, Optional, Any, List
from datetime import datetime

# pip install python-dotenv google-generativeai aiofiles pydantic tenacity pydantic-settings jinja2 rich
from dotenv import load_dotenv
from pydantic import ValidationError
import google.generativeai as genai
from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.prompt import Confirm

from src.config import AppConfig
from src.agent import GeminiAgent
from src.models import WorkflowResult
from src.data_loader import load_input_data
from src.logging_setup import setup_logging
from src.utils import safe_json_parse
from src.exceptions import ValidationFailedError, CacheCreationError

# [Global Console] Rich Consoleì€ ì „ì—­ì—ì„œ ì¬ì‚¬ìš©
console = Console()

def save_result_to_file(result: WorkflowResult, config: AppConfig):
    """[Config Injection] ê²°ê³¼ë¥¼ Markdown íŒŒì¼ë¡œ ì €ì¥ (í•˜ë“œì½”ë”© ì œê±°)"""
    output_dir = config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = output_dir / f"result_turn_{result.turn_id}_{timestamp}.md"
    
    content = f"""# Turn {result.turn_id} Result

## Query
{result.query}

## Evaluation
- **Best Candidate**: {result.evaluation.best_candidate}
- **Scores**:
{chr(10).join([f"  - {e.candidate_id}: {e.score} ({e.reason})" for e in result.evaluation.evaluations])}

## Best Answer ({result.evaluation.best_candidate})
{result.best_answer}

## Rewritten Answer
{result.rewritten_answer}

## Metadata
- **Cost**: ${result.cost:.4f}
- **Timestamp**: {timestamp}
"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    
    logging.getLogger("GeminiWorkflow").info(f"ê²°ê³¼ íŒŒì¼ ì €ì¥ë¨: {filename}")


async def _evaluate_and_rewrite_turn(
    agent: GeminiAgent,
    ocr_text: str,
    query: str,
    candidates: Dict[str, str],
    cache,
    turn_id: int,
    total_turns: int,
    logger: logging.Logger,
) -> Optional[WorkflowResult]:
    logger.info(f"Turn {turn_id}/{total_turns}: '{query}' ì‹¤í–‰ ì¤‘...")

    logger.info("í›„ë³´ í‰ê°€ ì¤‘...")
    evaluation = await agent.evaluate_responses(ocr_text, query, candidates, cached_content=cache)
    if not evaluation:
        logger.warning(f"Turn {turn_id}: í‰ê°€ ì‹¤íŒ¨")
        return None

    best_candidate_id = evaluation.get_best_candidate_id()
    logger.info(f"í›„ë³´ ì„ ì • ì™„ë£Œ: {best_candidate_id}")

    raw_answer = candidates.get(best_candidate_id, "")
    parsed = safe_json_parse(raw_answer, best_candidate_id)
    best_answer = parsed if parsed else raw_answer

    logger.info("ë‹µë³€ ì¬ì‘ì„± ì¤‘...")
    rewritten_answer = await agent.rewrite_best_answer(ocr_text, best_answer, cached_content=None)
    logger.info("ë‹µë³€ ì¬ì‘ì„± ì™„ë£Œ")

    return WorkflowResult(
        turn_id=turn_id,
        query=query,
        evaluation=evaluation,
        best_answer=best_answer,
        rewritten_answer=rewritten_answer,
        cost=agent.get_total_cost(),
        success=True,
    )


async def execute_workflow(agent: GeminiAgent, ocr_text: str, user_intent: Optional[str], logger: logging.Logger, ocr_filename: str, cand_filename: str, is_interactive: bool = True) -> List[WorkflowResult]:
    """
    [Orchestration] ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Iterative & Human-in-the-Loop)
    1. Planning: ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    2. Breakpoint: ì‚¬ìš©ì ê²€í†  ë° ë°ì´í„° Hot Reload (is_interactive=Trueì¼ ë•Œë§Œ)
    3. Execution Loop: ê° ì§ˆì˜ì— ëŒ€í•´ í‰ê°€ ë° ì¬ì‘ì„± ìˆ˜í–‰
    
    Args:
        is_interactive: Trueë©´ ì‚¬ìš©ìì—ê²Œ í™•ì¸ ìš”ì²­, Falseë©´ ìë™ ì§„í–‰ (AUTO ëª¨ë“œ)
    """
    # [Phase 1: Planning] ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    logger.info("ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    queries = await agent.generate_query(ocr_text, user_intent)
    
    if not queries:
        logger.error("ì§ˆì˜ ìƒì„± ì‹¤íŒ¨")
        return []

    # [Rich UI] ìƒì„±ëœ ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    console.print(Panel(
        "\n".join([f"{i+1}. {q}" for i, q in enumerate(queries)]),
        title="[bold green]Generated Strategic Queries[/bold green]",
        border_style="green"
    ))

    # [Conditional Interactivity] AUTO ëª¨ë“œì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ ê±´ë„ˆë›°ê¸°
    config = AppConfig()
    candidates = {}  # Initialize candidates
    
    if is_interactive:
        # [Breakpoint & Hot Reload] ì‚¬ìš©ì ê°œì…
        if Confirm.ask("ìœ„ ì§ˆì˜ë¥¼ ë³´ê³  í›„ë³´ ë‹µë³€ íŒŒì¼(input_candidates.json)ì„ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ìˆ˜ì • í›„ Enter)", default=True):
            logger.info("ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ë°ì´í„° ì¬ë¡œë”© ì¤‘...")
            try:
                _, candidates = await load_input_data(config.input_dir, ocr_filename, cand_filename)
                logger.info("ë°ì´í„° ì¬ë¡œë”© ì™„ë£Œ")
            except Exception as e:
                logger.error(f"ë°ì´í„° ì¬ë¡œë”© ì‹¤íŒ¨: {e}")
                return []
        else:
            # ì¬ë¡œë”© ì—†ì´ ì§„í–‰
            _, candidates = await load_input_data(config.input_dir, ocr_filename, cand_filename)
    else:
        # [AUTO Mode] ìë™ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ (í”„ë¡¬í”„íŠ¸ ì—†ìŒ)
        logger.info("AUTO ëª¨ë“œ: ë°ì´í„° ìë™ ë¡œë”© ì¤‘...")
        _, candidates = await load_input_data(config.input_dir, ocr_filename, cand_filename)

    # [Context Caching] ìºì‹œ ìƒì„± ì‹œë„
    logger.info("Context Caching ì‹œë„ ì¤‘...")
    try:
        cache = await agent.create_context_cache(ocr_text)
    except CacheCreationError as e:
        cache = None
        logger.warning(f"Context cache creation skipped: {e}")

    results = []
    
    # [Phase 2: Execution Loop] ìˆœì°¨ ì‹¤í–‰
    for i, query in enumerate(queries):
        turn_id = i + 1
        try:
            result = await _evaluate_and_rewrite_turn(
                agent=agent,
                ocr_text=ocr_text,
                query=query,
                candidates=candidates,
                cache=cache,
                turn_id=turn_id,
                total_turns=len(queries),
                logger=logger,
            )
            if not result:
                continue
            
            results.append(result)
            
            # ê²°ê³¼ ì €ì¥ (Config injection)
            save_result_to_file(result, config)
            
            # [Rich UI] í„´ ê²°ê³¼ ì¶œë ¥
            console.print(Panel(
                f"[bold]Query:[/bold] {query}\\n\\n"
                f"[bold]Best Candidate:[/bold] {result.evaluation.get_best_candidate_id()}\\n"
                f"[bold]Rewritten:[/bold] {result.rewritten_answer[:200]}...",
                title=f"Turn {turn_id} Result",
                border_style="blue"
            ))

            
        except Exception as e:
            logger.exception(f"Turn {turn_id} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
    # [Cleanup] ìºì‹œ ì‚­ì œ
    if cache:
        try:
            cache.delete()
            logger.info(f"Cache cleaned up: {cache.name}")
        except Exception as e:
            logger.warning(f"Cache cleanup failed: {e}")

    return results

async def main():
    """Main workflow orchestrator with professional argument parsing"""
    parser = argparse.ArgumentParser(
        description="ğŸš€ Advanced Gemini Workflow: AI-powered Q&A Evaluation System",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter  # Auto-show defaults
    )

    # 1. Core Configuration
    core_group = parser.add_argument_group("Core Configuration")
    core_group.add_argument(
        "--mode",
        type=str,
        choices=["AUTO", "CHAT"],
        default="AUTO",
        help="Execution mode"
    )

    # 2. Input Sources
    input_group = parser.add_argument_group("Input Sources")
    input_group.add_argument(
        "--ocr-file",
        type=str,
        default="input_ocr.txt",
        metavar="FILE",
        help="OCR text input file"
    )
    input_group.add_argument(
        "--cand-file",
        type=str,
        default="input_candidates.json",
        metavar="FILE",
        help="Candidate answers file (JSON)"
    )

    # 3. Chat Mode Options
    chat_group = parser.add_argument_group("Chat Mode Options")
    chat_group.add_argument(
        "--intent",
        type=str,
        default="Summarize the key points",
        help="User intent for CHAT mode"
    )

    args = parser.parse_args()

    # [Separation of Concerns] ë¡œê¹… ì„¤ì •ì„ ë³„ë„ ëª¨ë“ˆë¡œ ë¶„ë¦¬
    # from src.logging_setup import setup_logging # Already imported at the top
    # [Logging] Non-Blocking ë¡œê¹… ì´ˆê¸°í™” (logger, listener ë°˜í™˜)
    logger, log_listener = setup_logging()
    
    # [Configuration] Pydantic Settingsë¡œ í™˜ê²½ë³€ìˆ˜ì™€ ê¸°ë³¸ê°’ í†µí•© ê´€ë¦¬
    try:
        config = AppConfig()
        genai.configure(api_key=config.api_key)
    except ValidationError as e:
        logger.critical(f"ì„¤ì • ì˜¤ë¥˜: {e}")
        log_listener.stop()
        sys.exit(1)

    # [DI Preparation] Resources Initialization
    try:
        # 1. Jinja í™˜ê²½ì„ Mainì—ì„œ ìƒì„± (IoC ì›ì¹™)
        from jinja2 import Environment, FileSystemLoader
        
        if not config.template_dir.exists():
            raise FileNotFoundError(f"Templates directory missing: {config.template_dir}")
        
        jinja_env = Environment(
            loader=FileSystemLoader(config.template_dir),
            autoescape=True
        )
        
        # 2. ë°ì´í„° ë¡œë“œ (ì´ˆê¸° ë¡œë“œ)
        logger.info("ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘...")
        input_dir = config.input_dir
        ocr_text, _ = await load_input_data(input_dir, args.ocr_file, args.cand_file)
        
    except (FileNotFoundError, ValueError, json.JSONDecodeError, ValidationFailedError) as e:
        logger.critical(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        log_listener.stop()
        sys.exit(1)
    except Exception as e:
        logger.critical(f"Unexpected error during initialization: {e}")
        log_listener.stop()
        sys.exit(1)

    # [DI] Agentì— ëª¨ë“  ì˜ì¡´ì„± ì£¼ì…
    agent = GeminiAgent(config, jinja_env=jinja_env)
    user_intent = args.intent if args.mode == "CHAT" else None
    
    logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹œì‘ (Mode: {args.mode})")

    try:
        # [Separation of Concerns] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ëª¨ë“œì— ë”°ë¼ interactive ì„¤ì •)
        is_interactive = (args.mode == "CHAT")
        results = await execute_workflow(agent, ocr_text, user_intent, logger, args.ocr_file, args.cand_file, is_interactive)
        
        # [Cost Summary] ë¹„ìš© ì •ë³´ë¥¼ Panelë¡œ í‘œì‹œ
        total_cost = agent.get_total_cost()
        cost_info = f"""[bold cyan]ğŸ’° Total Session Cost:[/bold cyan] ${total_cost:.4f} USD
[bold green]ğŸ“Š Token Usage:[/bold green] {agent.total_input_tokens:,} input / {agent.total_output_tokens:,} output"""
        
        console.print()
        console.print(Panel(cost_info, title="[bold blue]Cost Summary[/bold blue]", border_style="blue"))
            
    except Exception as e:
        logger.exception(f"Workflow Failed: {e}")
    finally:
        # [Cleanup] ë¡œê·¸ ë¦¬ìŠ¤ë„ˆ ì¢…ë£Œ (ë‚¨ì€ ë¡œê·¸ í”ŒëŸ¬ì‹œ)
        log_listener.stop()

if __name__ == "__main__":
    load_dotenv()
    if os.name == 'nt':
        try:
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        except AttributeError:
            pass
    
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        # from rich.console import Console # Already imported at the top
        console.print("\n[bold red][!] ì‚¬ìš©ì ì¤‘ë‹¨[/bold red]")
        sys.exit(130)
    except Exception as e:
        logging.critical(f"Critical error: {e}", exc_info=True)
        sys.exit(1)
