# shining-quasar 프로젝트 개선 탐색 보고서

본 문서는 프로젝트 평가 결과를 바탕으로, 향후 수행해야 할 **미결(Pending) 개선 항목**을 정의합니다.

<!-- AUTO-SUMMARY-START -->
## 1. 전체 개선 요약

### 1.1 미결(Pending) 개선 항목 현황

프로젝트 코드베이스 분석 결과, 현재 보류 중인 개선 항목은 총 **1건**입니다.
대부분의 핵심 성능 최적화(OPT) 및 기능 구현이 완료되었으며, Gemini Batch API 연동 작업만이 유일한 미결 항목으로 남아 있습니다.

| 우선순위 | 미결 항목 수 | 상태 | 비고 |
|:---:|:---:|:---:|:---|
| **P1 (Critical)** | 0 | ✅ 완료 | 긴급한 문제는 발견되지 않음 |
| **P2 (High)** | 1 | 🔄 대기 중 | Batch API 연동 (`llm-batch-001`) |
| **P3 (Normal)** | 0 | ✅ 완료 | 추가 기능 요청 없음 |
| **OPT (Optimization)** | 0 | ✅ 완료 | Neo4j 및 Redis 최적화 적용됨 |

### 1.2 미결 개선 항목 목록

현재 진행이 필요한 작업 목록입니다.

| # | 항목명 | 우선순위 | 카테고리 | 대상 파일 |
|:---:|:---|:---:|:---|:---|
| 1 | Gemini Batch API 완전 구현 | **P2** | ⚙️ 기능 완성 | `src/llm/batch.py` |

> 📝 **참고:** 완료된 작업 이력은 `Session_History.md`에서 별도로 관리됩니다.
<!-- AUTO-SUMMARY-END -->

<!-- AUTO-IMPROVEMENT-LIST-START -->
## 2. 기능 개선 항목 (P1/P2)

> 📅 **평가 기준일:** 2025-12-16

### 🔴 긴급 (P1)

현재 식별된 치명적인(Critical) 오류나 긴급 수정이 필요한 항목은 없습니다.

### 🟡 중요 (P2)

유일한 P2 항목으로 Gemini Batch API 연동 작업이 남아 있습니다.

#### [P2-1] Gemini Batch API 완전 구현

| 항목 | 내용 |
|:---:|:---|
| **ID** | `llm-batch-001` |
| **카테고리** | ⚙️ 기능 완성 |
| **복잡도** | Medium |
| **대상 파일** | `src/llm/batch.py` |
| **Origin** | Static Analysis (Stub 주석 미해결) |
| **리스크 레벨** | Medium |
| **관련 평가** | 기능 완성도, 비용 효율성 |

**1. 현재 상태 및 문제점 (Problem):**

- `src/llm/batch.py` 파일 내 `GeminiBatchClient` 클래스가 존재하나, 실제 API 호출부는 **Stub(빈 껍데기)** 상태입니다.
- 배치 작업 상태를 로컬 메모리(`self._jobs`)에만 임시 저장하므로, 서버 재시작 시 작업 상태가 유실됩니다.
- 현재 구조로는 Gemini Batch API가 제공하는 **50% 비용 절감** 혜택을 전혀 누릴 수 없습니다.

**2. 영향 (Impact):**

- 대량의 문서 처리나 평가 작업을 수행할 때 불필요하게 높은 비용(Standard API 요금)이 발생합니다.
- 비동기 대량 처리가 불가능하여 시스템 리소스 활용도가 떨어집니다.

**3. 개선 내용 (Proposed Solution):**

- **실제 API 연동:** Google AI SDK를 사용하여 `submit_batch` 및 결과 조회 기능을 실제로 구현합니다.
- **영구 저장소 연동:** 배치 작업 상태(Job Status)를 Redis에 저장하여 서버 재시작 후에도 추적 가능하도록 개선합니다.
- **비용 추적 통합:** `CostTracker` 모듈과 연동하여 배치 처리 시 할인된 비용(50%)이 정확히 기록되도록 합니다.

**4. 기대 효과:**

- 대용량 데이터 처리 워크로드의 **비용 50% 절감**.
- 서버 재시작 등 장애 상황에서도 배치 작업의 연속성 보장.

**5. Definition of Done (완료 조건):**

- [ ] `submit_batch()` 메서드가 실제 Gemini API를 호출해야 함
- [ ] 작업 상태가 Redis에 저장되고 조회되어야 함 (`get_status()`)
- [ ] 관련 단위 테스트(`test_batch.py`)가 모킹(Mocking)된 환경에서 통과해야 함
- [ ] 타입 에러(Mypy) 및 린트 에러(Ruff)가 없어야 함
<!-- AUTO-IMPROVEMENT-LIST-END -->

<!-- AUTO-FEATURE-LIST-START -->
## 3. 기능 추가 항목 (P3)

> 📅 **평가 기준일:** 2025-12-16

### 🟢 일반 (P3)

현재 식별된 P3(Normal) 수준의 기능 추가 제안은 없습니다.

> 🎉 **참고:** 최근 `KG Provider` 모듈 추가 및 `Analysis` 엔진 기능 확장이 완료되어, 당분간은 시스템 안정화 및 P2 항목(Batch API) 해결에 집중하는 것이 권장됩니다.
<!-- AUTO-FEATURE-LIST-END -->

<!-- AUTO-OPTIMIZATION-START -->
## 4. 코드 품질 및 성능 최적화 (OPT)

> 📅 **평가 기준일:** 2025-12-16

### 4.1 일반 분석 결과

코드베이스에 대한 정적/동적 분석 결과는 다음과 같습니다:

- **데이터베이스 인덱싱:** 그래프 규모가 커짐에 따라 노드 속성 검색 속도 저하 우려가 있음. 명시적인 인덱스(Index) 생성 로직 보강 필요.
- **메모리 관리:** 대량 데이터 배치 처리 시 메모리 사용량에 대한 모니터링이 필요하나, 현재는 기본적인 메트릭만 수집 중.
- **코드 중복:** 주요 중복 없음. 유틸리티 함수 분리가 잘 되어 있음.

### 4.2 완료된 최적화 (참고)

- ✅ **[OPT-1] Neo4j 배치 트랜잭션:** `UNWIND` 구문 적용 완료.
- ✅ **[OPT-2] Redis 파이프라이닝:** `pipeline()` 적용 완료.

### 4.3 미결(Pending) 최적화 항목

반드시 수행해야 할 성능 최적화 항목이 1건 식별되었습니다.

#### [OPT-3] Neo4j 인덱스 및 쿼리 최적화

| 항목 | 내용 |
|:---:|:---|
| **ID** | `opt-cypher-index-001` |
| **카테고리** | 🚀 성능 튜닝 |
| **영향 범위** | 성능 (Graph Query Latency) |
| **대상 파일** | `src/graph/builder.py` |

**1. 현재 상태:**

- 노드 생성 시 `MERGE` 구문을 사용하고 있으나, 이를 뒷받침하는 인덱스(Index)나 유니크 제약조건(Constraint) 생성이 코드 레벨에서 명시적으로 관리되지 않고 있음.
- 데이터가 10만 건 이상으로 증가할 경우 `MERGE` 성능이 급격히 저하될 위험이 있음.

**2. 최적화 내용:**

- **인덱스 자동 생성:** 그래프 초기화 시(`GraphBuilder.__init__` 등) 주요 레이블(Rule, Topic, Document 등)의 핵심 속성에 대한 인덱스/제약조건 생성 쿼리 추가.
- **쿼리 튜닝:** 빈번하게 사용되는 검색 패턴에 대해 `PROFILE` 분석 후 최적화된 Cypher 구문 적용.

**3. 예상 효과:**

- 대규모 그래프 구축 및 검색 속도 **30% 이상 향상**.
- 중복 데이터 생성 방지 (데이터 무결성 확보).

**4. 측정 지표:**

- `Graph RAG` 질의 평균 응답 시간(Latency).
- 노드 삽입(Ingestion) 처리량(Throughput).

**5. Definition of Done:**

- [ ] `create_indices()` 메서드 구현 및 초기화 시 호출
- [ ] 주요 엔티티(Title, ID 등)에 대한 Index/Constraint 적용 확인
- [ ] 대량 데이터 삽입 테스트 시 성능 저하 없는지 검증
<!-- AUTO-OPTIMIZATION-END -->
