# -*- coding: utf-8 -*-
import argparse
import asyncio
import logging
import os
import sys
import contextlib
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import TYPE_CHECKING, Any, Awaitable, Dict, List, Optional, cast
from types import SimpleNamespace

from dotenv import load_dotenv
from rich.console import Console
from rich.panel import Panel
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TaskProgressColumn,
    TextColumn,
)
from rich.prompt import Confirm

from src.agent import GeminiAgent
from src.cache_analytics import analyze_cache_stats, print_cache_report
from src.config import AppConfig
from src.constants import (
    BUDGET_WARNING_THRESHOLDS,
    COST_PANEL_TEMPLATE,
    LOG_MESSAGES,
    PANEL_TITLE_BUDGET,
    PANEL_TITLE_COST,
    PANEL_TITLE_QUERIES,
    PANEL_TURN_BODY_TEMPLATE,
    PANEL_TURN_TITLE_TEMPLATE,
    PROGRESS_DONE_TEMPLATE,
    PROGRESS_FAILED_TEMPLATE,
    PROGRESS_PROCESSING_TEMPLATE,
    PROGRESS_RESTORED_TEMPLATE,
    PROGRESS_WAITING_TEMPLATE,
    PROMPT_EDIT_CANDIDATES,
    USER_INTERRUPT_MESSAGE,
)
from src.data_loader import load_input_data, reload_data_if_needed
from src.exceptions import (
    APIRateLimitError,
    BudgetExceededError,
    CacheCreationError,
    SafetyFilterError,
    ValidationFailedError,
)
from src.logging_setup import log_metrics, setup_logging
from src.models import WorkflowResult
from src.utils import (
    append_checkpoint,
    load_checkpoint,
    safe_json_parse,
    write_cache_stats,
)

if TYPE_CHECKING:
    from google.generativeai import caching


genai = SimpleNamespace(configure=lambda *_args, **_kwargs: None)

# Rich Consoleì€ ì „ì—­ì—ì„œ ì¬ì‚¬ìš©
console = Console()


@dataclass
class WorkflowContext:
    agent: GeminiAgent
    config: AppConfig
    logger: logging.Logger
    ocr_text: str
    candidates: Dict[str, str]
    cache: Optional["caching.CachedContent"]
    total_turns: int
    checkpoint_path: Optional[Path]
    progress: Optional[Progress] = None


def save_result_to_file(result: WorkflowResult, config: AppConfig) -> None:
    """ê²°ê³¼ë¥¼ Markdown íŒŒì¼ë¡œ ì €ì¥ (í•˜ë“œì½”ë”© ì œê±°)"""
    assert result.evaluation is not None
    output_dir = config.output_dir
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = output_dir / f"result_turn_{result.turn_id}_{timestamp}.md"

    content = f"""# Turn {result.turn_id} Result

## Query
{result.query}

## Evaluation
- **Best Candidate**: {result.evaluation.best_candidate}
- **Scores**:
{chr(10).join([f"  - {e.candidate_id}: {e.score} ({e.reason})" for e in result.evaluation.evaluations])}

## Best Answer ({result.evaluation.best_candidate})
{result.best_answer}

## Rewritten Answer
{result.rewritten_answer}

## Metadata
- **Cost**: ${result.cost:.4f}
- **Timestamp**: {timestamp}
"""
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)

    logging.getLogger("GeminiWorkflow").info(f"ê²°ê³¼ íŒŒì¼ ì €ì¥ë¨: {filename}")


def _warn_budget_thresholds(agent: GeminiAgent, logger: logging.Logger) -> None:
    """Emit one-time budget warnings at configured thresholds."""
    usage = agent.get_budget_usage_percent()
    for threshold, severity in BUDGET_WARNING_THRESHOLDS:
        attr_name = f"_warned_{threshold}"
        if usage >= threshold and not hasattr(agent, attr_name):
            logger.warning(f"{severity}: Budget at {usage:.1f}%")
            setattr(agent, attr_name, True)


def _display_queries(queries: List[str]) -> None:
    """ìƒì„±ëœ ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ Rich Panelë¡œ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        queries: ì¶œë ¥í•  ì§ˆì˜ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
    """
    console.print(
        Panel(
            "\n".join([f"{i + 1}. {q}" for i, q in enumerate(queries)]),
            title=PANEL_TITLE_QUERIES,
            border_style="green",
        )
    )


def _render_cost_panel(agent: GeminiAgent) -> Panel:
    """ë¹„ìš©, í† í° ì‚¬ìš©ëŸ‰, ìºì‹œ í†µê³„ë¥¼ í‘œì‹œí•˜ëŠ” Rich Panelì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        agent: ì‚¬ìš©ëŸ‰ í†µê³„ë¥¼ í¬í•¨í•˜ëŠ” GeminiAgent ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ë¹„ìš© ë° ì‚¬ìš©ëŸ‰ ì •ë³´ê°€ ì„¤ì •ëœ Rich Panel ê°ì²´
    """
    cost_fn = getattr(agent, "get_total_cost", None)
    cost_info = COST_PANEL_TEMPLATE.format(
        cost=cost_fn() if callable(cost_fn) else 0.0,
        input_tokens=agent.total_input_tokens,
        output_tokens=agent.total_output_tokens,
        cache_hits=agent.cache_hits,
        cache_misses=agent.cache_misses,
    )
    return Panel(cost_info, title=PANEL_TITLE_COST, border_style="blue")


def _render_budget_panel(agent: GeminiAgent) -> Panel:
    usage_fn = getattr(agent, "get_budget_usage_percent", None)
    usage = usage_fn() if callable(usage_fn) else 0.0
    content = f"Budget usage: {usage:.2f}%"
    return Panel(content, title=PANEL_TITLE_BUDGET, border_style="red")


def _resolve_checkpoint_path(
    config: AppConfig, checkpoint_path: Optional[Path]
) -> Path:
    """ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê²°ì •í•©ë‹ˆë‹¤.

    Args:
        config: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ê°ì²´
        checkpoint_path: CLI ì¸ìë¡œ ì œê³µëœ ì„ íƒì  ê²½ë¡œ

    Returns:
        ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ
    """
    path = checkpoint_path or (config.output_dir / "checkpoint.jsonl")
    if not path.is_absolute():
        path = config.output_dir / path
    return path


async def _load_checkpoint_records(
    checkpoint_path: Path, resume: bool, logger: logging.Logger
) -> Dict[str, WorkflowResult]:
    """ì¬ê°œ ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš° ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ê¸°ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        resume: ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í”Œë˜ê·¸
        logger: ìƒíƒœ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë¡œê±° ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ì§ˆì˜ ë¬¸ìì—´ì„ WorkflowResult ê°ì²´ë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    if not resume:
        return {}
    records = await load_checkpoint(checkpoint_path)
    if records:
        logger.info(
            f"Resume enabled: {len(records)} completed turn(s) preloaded from {checkpoint_path}"
        )
    return records


async def _load_candidates(
    config: AppConfig,
    ocr_filename: str,
    cand_filename: str,
    is_interactive: bool,
    logger: logging.Logger,
) -> Optional[Dict[str, str]]:
    """í›„ë³´ ë‹µë³€ì„ ë¡œë“œí•˜ë©°, ëŒ€í™”í˜• ëª¨ë“œì—ì„œëŠ” ì„ íƒì ìœ¼ë¡œ ì¬ë¡œë“œë¥¼ í”„ë¡¬í”„íŠ¸í•©ë‹ˆë‹¤.

    Args:
        config: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ê°ì²´
        ocr_filename: OCR ì…ë ¥ íŒŒì¼ëª…
        cand_filename: í›„ë³´ ë‹µë³€ ì…ë ¥ íŒŒì¼ëª…
        is_interactive: ëŒ€í™”í˜• ëª¨ë“œ í”Œë˜ê·¸
        logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤

    Returns:
        í›„ë³´ ë‹µë³€ ë”•ì…”ë„ˆë¦¬, ë¡œë“œ ì‹¤íŒ¨ ì‹œ None
    """
    if is_interactive and Confirm.ask(PROMPT_EDIT_CANDIDATES, default=True):
        logger.info("ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ë°ì´í„° ì¬ë¡œë”© ì¤‘...")
        try:
            _, candidates = await reload_data_if_needed(
                config, ocr_filename, cand_filename
            )
            logger.info("ë°ì´í„° ì¬ë¡œë”© ì™„ë£Œ")
            return candidates
        except (ValidationFailedError, FileNotFoundError, ValueError) as e:
            logger.error(LOG_MESSAGES["reload_failed"].format(error=e))
            return None

    # ì¬ë¡œë”© ì—†ì´ ì§„í–‰ (AUTO ë˜ëŠ” skip)
    if not is_interactive:
        logger.info("AUTO ëª¨ë“œ: ë°ì´í„° ìë™ ë¡œë”© ì¤‘...")
    else:
        logger.info("ì¬ë¡œë”© ì—†ì´ ì§„í–‰")
    _, candidates = await reload_data_if_needed(config, ocr_filename, cand_filename)
    return candidates


async def _create_context_cache(
    agent: GeminiAgent, ocr_text: str, logger: logging.Logger
) -> Optional["caching.CachedContent"]:
    """OCR í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ìºì‹œ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤.

    Args:
        agent: GeminiAgent ì¸ìŠ¤í„´ìŠ¤
        ocr_text: ìºì‹œí•  OCR í…ìŠ¤íŠ¸ ë‚´ìš©
        logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤

    Returns:
        ì„±ê³µ ì‹œ CachedContent ê°ì²´, ì‹¤íŒ¨ ì‹œ None
    """
    logger.info("Context Caching ì‹œë„ ì¤‘...")
    try:
        return await agent.create_context_cache(ocr_text)
    except CacheCreationError as e:
        logger.warning(LOG_MESSAGES["cache_skipped"].format(error=e))
        return None


def _schedule_turns(
    queries: List[str],
    agent: GeminiAgent,
    config: AppConfig,
    logger: logging.Logger,
    ocr_text: str,
    candidates: Dict[str, str],
    cache: Optional["caching.CachedContent"],
    checkpoint_records: Dict[str, WorkflowResult],
    checkpoint_path: Path,
    progress: Progress,
    resume: bool,
) -> tuple[List[WorkflowResult], List[Awaitable[Optional[WorkflowResult]]]]:
    """í„´ ì‘ì—…ì„ ì¤€ë¹„í•˜ë©°, ì˜ˆì‚° í™•ì¸, ì²´í¬í¬ì¸íŠ¸, ì§„í–‰ í‘œì‹œì¤„ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        queries: ì²˜ë¦¬í•  ì§ˆì˜ ë¦¬ìŠ¤íŠ¸
        agent: GeminiAgent ì¸ìŠ¤í„´ìŠ¤
        config: ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
        logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
        ocr_text: OCR í…ìŠ¤íŠ¸ ë‚´ìš©
        candidates: í›„ë³´ ë‹µë³€ ë”•ì…”ë„ˆë¦¬
        cache: ì„ íƒì  ì»¨í…ìŠ¤íŠ¸ ìºì‹œ
        checkpoint_records: ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸ ê¸°ë¡ ë”•ì…”ë„ˆë¦¬
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        progress: Rich Progress ì¸ìŠ¤í„´ìŠ¤
        resume: ì¬ê°œ ëª¨ë“œ í”Œë˜ê·¸

    Returns:
        ë³µì›ëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì™€ ëŒ€ê¸° ê°€ëŠ¥í•œ ì‘ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” Tuple
    """
    results: List[WorkflowResult] = []
    tasks: List[Awaitable[Optional[WorkflowResult]]] = []

    for i, query in enumerate(queries):
        # Budget check before scheduling turn
        try:
            agent.check_budget()
        except BudgetExceededError as e:
            logger.error(LOG_MESSAGES["budget_exceeded"].format(error=e))
            console.print(Panel(str(e), title=PANEL_TITLE_BUDGET, border_style="red"))
            break

        _warn_budget_thresholds(agent, logger)

        turn_id = i + 1
        task_id = progress.add_task(
            PROGRESS_WAITING_TEMPLATE.format(turn_id=turn_id), total=1
        )

        if resume and query in checkpoint_records:
            restored = checkpoint_records[query]
            restored.turn_id = turn_id
            results.append(restored)
            progress.update(
                task_id,
                advance=1,
                description=PROGRESS_RESTORED_TEMPLATE.format(turn_id=turn_id),
            )
            continue

        tasks.append(
            process_single_query(
                ctx=WorkflowContext(
                    agent=agent,
                    config=config,
                    logger=logger,
                    ocr_text=ocr_text,
                    candidates=candidates,
                    cache=cache,
                    total_turns=len(queries),
                    checkpoint_path=checkpoint_path,
                    progress=progress,
                ),
                query=query,
                turn_id=turn_id,
                task_id=task_id,
            )
        )

    return results, tasks


async def _gather_results(
    tasks: List[Awaitable[Optional[WorkflowResult]]],
    logger: logging.Logger,
) -> List[WorkflowResult]:
    """Execute scheduled tasks and collect successful results.

    Args:
        tasks: List of awaitable tasks returning Optional[WorkflowResult].
        logger: Logger instance.

    Returns:
        List of successfully completed WorkflowResult objects.
    """
    if not tasks:
        return []

    filtered: List[WorkflowResult] = []
    processed_results = await asyncio.gather(*tasks, return_exceptions=True)
    for item in processed_results:
        if isinstance(item, Exception):
            logger.error(LOG_MESSAGES["turn_exception"].format(error=item))
            continue
        if item is None:
            continue
        filtered.append(cast(WorkflowResult, item))
    return filtered


async def _evaluate_and_rewrite_turn(
    ctx: WorkflowContext,
    query: str,
    turn_id: int,
) -> Optional[WorkflowResult]:
    ctx.logger.info(f"Turn {turn_id}/{ctx.total_turns}: '{query}' ì‹¤í–‰ ì¤‘...")

    ctx.logger.info("í›„ë³´ í‰ê°€ ì¤‘...")
    evaluation = await ctx.agent.evaluate_responses(
        ctx.ocr_text, query, ctx.candidates, cached_content=ctx.cache
    )
    if evaluation is None:
        ctx.logger.warning(f"Turn {turn_id}: í‰ê°€ ì‹¤íŒ¨")
        return None

    best_candidate_id = evaluation.get_best_candidate_id()
    ctx.logger.info(f"í›„ë³´ ì„ ì • ì™„ë£Œ: {best_candidate_id}")

    raw_answer = ctx.candidates.get(best_candidate_id, "")
    parsed = safe_json_parse(raw_answer, best_candidate_id)
    best_answer = parsed if parsed else raw_answer

    ctx.logger.info("ë‹µë³€ ì¬ì‘ì„± ì¤‘...")
    rewritten_answer = await ctx.agent.rewrite_best_answer(
        ctx.ocr_text, best_answer, cached_content=None
    )
    ctx.logger.info("ë‹µë³€ ì¬ì‘ì„± ì™„ë£Œ")

    return WorkflowResult(
        turn_id=turn_id,
        query=query,
        evaluation=evaluation,
        best_answer=best_answer,
        rewritten_answer=rewritten_answer,
        cost=ctx.agent.get_total_cost(),
        success=True,
    )


async def process_single_query(
    ctx: WorkflowContext,
    query: str,
    turn_id: int,
    task_id: Optional[Any] = None,
) -> Optional[WorkflowResult]:
    """
    ë‹¨ì¼ ì§ˆì˜ ì²˜ë¦¬ (í‰ê°€ -> ì¬ì‘ì„±)
    """
    try:
        # Update progress description
        if ctx.progress and task_id:
            ctx.progress.update(
                task_id,
                description=PROGRESS_PROCESSING_TEMPLATE.format(turn_id=turn_id),
            )

        result = await _evaluate_and_rewrite_turn(ctx=ctx, query=query, turn_id=turn_id)

        if result:
            # ê²°ê³¼ ì €ì¥
            assert result.evaluation is not None
            save_result_to_file(result, ctx.config)
            if ctx.checkpoint_path:
                await append_checkpoint(ctx.checkpoint_path, result)

            # í„´ ê²°ê³¼ ì¶œë ¥ (Thread-safe way needed for real app, but Rich handles it reasonably well)
            console.print(
                Panel(
                    PANEL_TURN_BODY_TEMPLATE.format(
                        query=query,
                        best_candidate=result.evaluation.get_best_candidate_id(),
                        rewritten=result.rewritten_answer[:200],
                    ),
                    title=PANEL_TURN_TITLE_TEMPLATE.format(turn_id=turn_id),
                    border_style="blue",
                )
            )

            # Mark task as completed
            if ctx.progress and task_id:
                ctx.progress.update(
                    task_id,
                    advance=1,
                    description=PROGRESS_DONE_TEMPLATE.format(turn_id=turn_id),
                )

            return result

    except (APIRateLimitError, ValidationFailedError, SafetyFilterError) as e:
        ctx.logger.error(f"ë³µêµ¬ ê°€ëŠ¥ ì˜¤ë¥˜ë¡œ í„´ {turn_id}ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤: {e}")
        if ctx.progress and task_id:
            ctx.progress.update(
                task_id,
                description=PROGRESS_FAILED_TEMPLATE.format(turn_id=turn_id),
            )
        return None
    except BudgetExceededError as e:
        ctx.logger.critical(f"ì˜ˆì‚° ì´ˆê³¼ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤: {e}")
        if ctx.progress and task_id:
            ctx.progress.update(
                task_id,
                description=PROGRESS_FAILED_TEMPLATE.format(turn_id=turn_id),
            )
        raise
    except Exception as e:
        ctx.logger.exception(LOG_MESSAGES["turn_exception"].format(error=e))
        if ctx.progress and task_id:
            ctx.progress.update(
                task_id,
                description=PROGRESS_FAILED_TEMPLATE.format(turn_id=turn_id),
            )

    return None


async def execute_workflow(
    agent: GeminiAgent,
    ocr_text: str,
    user_intent: Optional[str],
    logger: logging.Logger,
    ocr_filename: str,
    cand_filename: str,
    is_interactive: bool = True,
    resume: bool = False,
    checkpoint_path: Optional[Path] = None,
    keep_progress: bool = False,
) -> List[WorkflowResult]:
    """ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ì§ˆì˜ ìƒì„± â†’ í‰ê°€ â†’ ì¬ì‘ì„±).

    ë‹¨ê³„:
    1. ì§ˆì˜ ìƒì„±: OCR + ì‚¬ìš©ì ì˜ë„ ê¸°ë°˜
    2. ëŒ€í™”í˜• ëª¨ë“œ: í›„ë³´ ë‹µë³€ ìˆ˜ì • ê°€ëŠ¥ (ì„ íƒ)
    3. ë³‘ë ¬ í‰ê°€: ê° ì§ˆì˜ì— ëŒ€í•´ í›„ë³´ í‰ê°€ ë° ì¬ì‘ì„±
    4. ì²´í¬í¬ì¸íŠ¸: ì™„ë£Œëœ ì§ˆì˜ëŠ” ì¬ì‹¤í–‰ ê±´ë„ˆëœ€

    Args:
        agent: Gemini API ì—ì´ì „íŠ¸
        ocr_text: ì…ë ¥ OCR í…ìŠ¤íŠ¸
        user_intent: ì‚¬ìš©ì ì˜ë„ (ì„ íƒ)
        logger: ë¡œê±° ì¸ìŠ¤í„´ìŠ¤
        ocr_filename: OCR íŒŒì¼ëª… (ì¬ë¡œë”©ìš©)
        cand_filename: í›„ë³´ íŒŒì¼ëª… (ì¬ë¡œë”©ìš©)
        is_interactive: ëŒ€í™”í˜• ëª¨ë“œ í™œì„±í™” ì—¬ë¶€
        resume: ì²´í¬í¬ì¸íŠ¸ ë³µêµ¬ ì—¬ë¶€
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        keep_progress: ì™„ë£Œ í›„ì—ë„ Progress Barë¥¼ ìœ ì§€í• ì§€ ì—¬ë¶€

    Returns:
        ê° ì§ˆì˜ë³„ í‰ê°€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    # ... (Phase 1: Planning - same as before)
    # ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    logger.info("ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    queries = await agent.generate_query(ocr_text, user_intent)

    if not queries:
        logger.error("ì§ˆì˜ ìƒì„± ì‹¤íŒ¨")
        return []

    # ìƒì„±ëœ ì§ˆì˜ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    _display_queries(queries)

    # AUTO ëª¨ë“œì—ì„œëŠ” í”„ë¡¬í”„íŠ¸ ê±´ë„ˆë›°ê¸°
    config = AppConfig()  # type: ignore[call-arg]
    candidates: Optional[Dict[str, str]] = None
    checkpoint_path = _resolve_checkpoint_path(config, checkpoint_path)
    checkpoint_records = await _load_checkpoint_records(checkpoint_path, resume, logger)

    candidates = await _load_candidates(
        config=config,
        ocr_filename=ocr_filename,
        cand_filename=cand_filename,
        is_interactive=is_interactive,
        logger=logger,
    )
    if candidates is None:
        return []

    # ìºì‹œ ìƒì„± ì‹œë„ (Context Caching)
    cache = await _create_context_cache(agent, ocr_text, logger)

    # ë³‘ë ¬ ì‹¤í–‰ (Parallel Processing) with Progress Bar
    logger.info(f"ì´ {len(queries)}ê°œì˜ ì§ˆì˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")

    results: List[WorkflowResult] = []

    # Rich Progress Bar Context
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        console=console,
        transient=not keep_progress,  # ë””ë²„ê¹… ì‹œ ê¸°ë¡ ìœ ì§€ ì˜µì…˜
    ) as progress:
        restored_results, tasks = _schedule_turns(
            queries=queries,
            agent=agent,
            config=config,
            logger=logger,
            ocr_text=ocr_text,
            candidates=candidates,
            cache=cache,
            checkpoint_records=checkpoint_records,
            checkpoint_path=checkpoint_path,
            progress=progress,
            resume=resume,
        )
        results.extend(restored_results)

        # ëª¨ë“  íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰ (ì—ëŸ¬ ìˆ˜ì§‘)
        results.extend(await _gather_results(tasks, logger))

        # ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ turn_idë¡œ ì •ë ¬ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìˆœì„œê°€ ì„ì¼ ìˆ˜ ìˆìŒ)
        results.sort(key=lambda x: x.turn_id)

    # ìºì‹œ ì‚­ì œ (Cleanup)
    if cache:
        try:
            cache.delete()
            logger.info(f"Cache cleaned up: {cache.name}")
        except Exception as e:
            logger.warning(f"Cache cleanup failed: {e}")

    return results


async def main():
    """Main workflow orchestrator with professional argument parsing"""
    parser = argparse.ArgumentParser(
        description="ğŸš€ Advanced Gemini Workflow: AI-powered Q&A Evaluation System",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,  # Auto-show defaults
    )

    # 1. Core Configuration
    core_group = parser.add_argument_group("Core Configuration")
    core_group.add_argument(
        "--mode",
        type=str,
        choices=["AUTO", "CHAT"],
        default="AUTO",
        help="Execution mode",
    )
    core_group.add_argument(
        "--interactive",
        action="store_true",
        help="Force interactive mode (ask for confirmation) even in AUTO mode",
    )

    io_group = parser.add_argument_group("Input/Output")
    io_group.add_argument(
        "--ocr-file",
        type=str,
        default="input_ocr.txt",
        help="OCR input filename (relative to data/inputs by default)",
    )
    io_group.add_argument(
        "--cand-file",
        type=str,
        default="input_candidates.json",
        help="Candidate answers filename (relative to data/inputs by default)",
    )
    core_group.add_argument(
        "--intent",
        type=str,
        default=None,
        help="Optional user intent to guide query generation",
    )
    io_group.add_argument(
        "--checkpoint-file",
        type=str,
        default="checkpoint.jsonl",
        help="Checkpoint JSONL path (relative paths resolve under data/outputs)",
    )
    debug_group = parser.add_argument_group("Debugging")
    debug_group.add_argument(
        "--keep-progress",
        action="store_true",
        help="Keep progress bar visible after completion (for debugging)",
    )
    debug_group.add_argument(
        "--no-cost-panel",
        action="store_true",
        help="Skip cost panel summary output",
    )
    debug_group.add_argument(
        "--no-budget-panel",
        action="store_true",
        help="Skip budget panel summary output",
    )
    core_group.add_argument(
        "--resume",
        action="store_true",
        help="Resume workflow using checkpoint file (skips completed queries)",
    )
    core_group.add_argument(
        "--log-level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        default=None,
        help="Override log level (otherwise from LOG_LEVEL env)",
    )
    core_group.add_argument(
        "--analyze-cache",
        action="store_true",
        help="Print cache stats summary and exit",
    )

    # ... (rest of arguments)

    args = parser.parse_args()

    # ... (logging setup)
    logger, log_listener = setup_logging(log_level=args.log_level)
    start_time = datetime.now(timezone.utc)

    # ... (config & resource loading)
    try:
        config = AppConfig()
        import google.generativeai as genai

        genai.configure(api_key=config.api_key)
        # ... (jinja env setup)
        from jinja2 import Environment, FileSystemLoader

        if not config.template_dir.exists():
            raise FileNotFoundError(
                f"Templates directory missing: {config.template_dir}"
            )
        jinja_env = Environment(
            loader=FileSystemLoader(config.template_dir), autoescape=True
        )

        logger.info("ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘...")
        input_dir = config.input_dir
        ocr_text, _ = await load_input_data(input_dir, args.ocr_file, args.cand_file)

    except Exception as e:
        # ... (error handling)
        logger.critical(f"[FATAL] Initialization failed: {e}")
        log_listener.stop()
        sys.exit(1)

    # Agentì— ëª¨ë“  ì˜ì¡´ì„± ì£¼ì… (Dependency Injection)
    agent = GeminiAgent(config, jinja_env=jinja_env)
    user_intent = args.intent if args.mode == "CHAT" else None

    logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹œì‘ (Mode: {args.mode})")

    try:
        # Cache analytics quick path
        if args.analyze_cache:
            summary = analyze_cache_stats(config.cache_stats_path)
            print_cache_report(summary)
            log_listener.stop()
            return

        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ëª¨ë“œì— ë”°ë¼ interactive ì„¤ì •)
        # CHAT ëª¨ë“œì´ê±°ë‚˜ --interactive í”Œë˜ê·¸ê°€ ìˆìœ¼ë©´ ëŒ€í™”í˜• ëª¨ë“œ
        is_interactive = (args.mode == "CHAT") or args.interactive
        checkpoint_path = Path(args.checkpoint_file)
        if not checkpoint_path.is_absolute():
            checkpoint_path = config.output_dir / checkpoint_path

        await execute_workflow(
            agent,
            ocr_text,
            user_intent,
            logger,
            args.ocr_file,
            args.cand_file,
            is_interactive,
            resume=args.resume,
            checkpoint_path=checkpoint_path,
            keep_progress=args.keep_progress,
        )

        # ... (rest of main)

        # ë¹„ìš© ì •ë³´ë¥¼ Panelë¡œ í‘œì‹œ
        console.print()
        no_budget_panel = getattr(args, "no_budget_panel", False)
        no_cost_panel = getattr(args, "no_cost_panel", False)
        if not no_budget_panel:
            console.print(_render_budget_panel(agent))
        if not no_cost_panel:
            console.print(_render_cost_panel(agent))

        # Cache stats persistence: append JSONL entry with small retention window
        try:
            cache_entry = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "model": config.model_name,
                "input_tokens": agent.total_input_tokens,
                "output_tokens": agent.total_output_tokens,
                "cache_hits": agent.cache_hits,
                "cache_misses": agent.cache_misses,
            }
            write_cache_stats(
                config.cache_stats_path, config.cache_stats_max_entries, cache_entry
            )
            logger.info(f"Cache stats saved to {config.cache_stats_path}")
        except Exception as e:
            if hasattr(logger, "warning"):
                logger.warning(f"Cache stats write skipped: {e}")
                logger.warning("cache_stats_write_failed")
            else:
                print(f"Cache stats write skipped: {e}")

    except (
        APIRateLimitError,
        ValidationFailedError,
        SafetyFilterError,
        BudgetExceededError,
    ) as e:
        logger.exception(LOG_MESSAGES["workflow_failed"].format(error=e))
    except Exception as e:
        logger.exception(LOG_MESSAGES["workflow_failed"].format(error=e))
    finally:
        # ë¡œê·¸ ë¦¬ìŠ¤ë„ˆ ì¢…ë£Œ (ë‚¨ì€ ë¡œê·¸ í”ŒëŸ¬ì‹œ)
        with contextlib.suppress(Exception):
            elapsed_ms = (
                datetime.now(timezone.utc) - start_time
            ).total_seconds() * 1000
            log_metrics(
                logger,
                latency_ms=elapsed_ms,
                prompt_tokens=getattr(agent, "total_input_tokens", 0),
                completion_tokens=getattr(agent, "total_output_tokens", 0),
                cache_hits=getattr(agent, "cache_hits", 0),
                cache_misses=getattr(agent, "cache_misses", 0),
            )
        log_listener.stop()


if __name__ == "__main__":
    load_dotenv()
    if os.name == "nt":
        try:
            policy = getattr(asyncio, "WindowsSelectorEventLoopPolicy", None)
            if policy:
                asyncio.set_event_loop_policy(policy())
        except AttributeError:
            pass

    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        # from rich.console import Console # Already imported at the top
        console.print(USER_INTERRUPT_MESSAGE)
        sys.exit(130)
    except Exception as e:  # noqa: BLE001
        logging.critical(f"Critical error: {e}", exc_info=True)
        sys.exit(1)
